from fastapi import FastAPI, Request, Depends, HTTPException, Query, status, Security
from fastapi.security import APIKeyHeader, OAuth2PasswordBearer
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from fastapi.middleware.cors import CORSMiddleware
from strawberry.fastapi import GraphQLRouter
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend
from fastapi_cache.decorator import cache
from fastapi_cache.coder import JsonCoder
from redis import asyncio as aioredis
from pydantic import BaseModel, Field, validator
from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from jose import JWTError, jwt
from datetime import datetime, timedelta, date
# import os # os and load_dotenv are now handled in server.db
import logging
from typing import Any, Dict, List, Optional, TypeVar, Generic, Tuple
import json
import asyncio
import os
from contextlib import asynccontextmanager
import math
import base64
import httpx
from enum import Enum

# ‰ªéÊàë‰ª¨ÁöÑÊ®°ÂùóÂØºÂÖ•
from api.graphql_schema import schema as gql_schema # Renamed to avoid conflict with strawberry.Schema
from api.auth_routes import router as auth_router # Import auth routes
import db as db_module # Import the module itself
from db import init_db_pool, close_db_pool, get_db_conn_dependency # Import specific functions
from utils import static_data as static_data_utils

# Standardized API Response Models
T = TypeVar('T')

class PaginationInfo(BaseModel):
    total: int
    page: int = 1
    page_size: int = 20
    pages: int
    has_next: bool
    has_prev: bool
    next_cursor: Optional[str] = None

class ErrorInfo(BaseModel):
    code: str
    message: str
    details: Optional[Dict[str, Any]] = None

class APIResponse(BaseModel, Generic[T]):
    status: str = "success"
    data: Optional[T] = None
    pagination: Optional[PaginationInfo] = None
    error: Optional[ErrorInfo] = None

# Response Factory Functions
def success_response(data: Any = None, pagination: Optional[PaginationInfo] = None) -> Dict[str, Any]:
    return APIResponse(status="success", data=data, pagination=pagination).dict()

def error_response(code: str, message: str, status_code: int, details: Optional[Dict[str, Any]] = None) -> JSONResponse:
    return JSONResponse(
        status_code=status_code,
        content=APIResponse(status="error", error=ErrorInfo(code=code, message=message, details=details)).dict(exclude_none=True)
    )

# Error Codes
class ErrorCodes:
    VALIDATION_ERROR = "VALIDATION_ERROR"
    AUTHENTICATION_ERROR = "AUTHENTICATION_ERROR"
    AUTHORIZATION_ERROR = "AUTHORIZATION_ERROR"
    RESOURCE_NOT_FOUND = "RESOURCE_NOT_FOUND"
    RATE_LIMIT_EXCEEDED = "RATE_LIMIT_EXCEEDED"
    INTERNAL_SERVER_ERROR = "INTERNAL_SERVER_ERROR"
    BAD_REQUEST = "BAD_REQUEST"

# --- Security Configurations ---

# API Key Authentication
API_KEY = os.getenv("API_KEY", "your_default_dev_api_key") # Get API Key from environment
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

async def get_api_key(api_key_header: str = Security(api_key_header)):
    if api_key_header is None:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="API key is missing")
    if api_key_header != API_KEY:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Invalid API Key")
    return api_key_header

# Rate Limiting
limiter = Limiter(key_func=get_remote_address)

# JWT Authentication
SECRET_KEY = os.getenv("SECRET_KEY", "a_very_secret_key_for_development")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/token") # Placeholder token URL

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# Placeholder for user model and DB interaction
class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None

async def get_user(username: str):
    # This is a placeholder. In a real app, you'd query the database.
    if username == "johndoe":
        return User(username="johndoe", email="johndoe@example.com", full_name="John Doe")
    return None

async def get_current_user(token: str = Depends(oauth2_scheme)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    user = await get_user(username=username)
    if user is None:
        raise credentials_exception
    return user

# Input Validation Model
class PropertyCreate(BaseModel):
    title: str = Field(..., min_length=3, max_length=100)
    description: str = Field(..., min_length=10)
    price: float = Field(..., gt=0)
    bedrooms: int = Field(..., ge=0)
    available_from: date
    
    @validator('title')
    def title_must_be_valid(cls, v):
        if '<script>' in v.lower():
            raise ValueError('Title cannot contain script tags')
        return v
    
    @validator('price')
    def price_must_be_reasonable(cls, v):
        if v > 10000000: # Set a reasonable max price
            raise ValueError('Price is out of reasonable range')
        return v

# --- End Security Configurations ---


# Pydantic Models for Pagination
class PaginationParams:
    def __init__(
        self,
        page: int = Query(1, ge=1, description="È°µÁ†ÅÔºå‰ªé1ÂºÄÂßã"),
        page_size: int = Query(20, ge=1, le=100, description="ÊØèÈ°µÈ°πÁõÆÊï∞"),
        cursor: Optional[str] = Query(None, description="Ê∏∏Ê†áÂÄºÔºàÁî®‰∫éÊ∏∏Ê†áÂàÜÈ°µÔºâ")
    ):
        self.page = page
        self.page_size = page_size
        self.cursor = cursor


# Cursor helper functions
def encode_cursor(value: Any) -> str:
    return base64.urlsafe_b64encode(str(value).encode('utf-8')).decode('utf-8')

def decode_cursor(cursor: str) -> str:
    return base64.urlsafe_b64decode(cursor.encode('utf-8')).decode('utf-8')

# Asynchronous pagination logic adapted for psycopg2
async def paginate_query(db_conn: Any, query: str, count_query: str, params: tuple, pagination: PaginationParams) -> Tuple[List[Dict], PaginationInfo]:
    def _db_calls():
        with db_conn.cursor() as cursor:
            cursor.execute(count_query, params)
            total = cursor.fetchone()[0]
            
            offset = (pagination.page - 1) * pagination.page_size
            paginated_query = f"{query} LIMIT %s OFFSET %s"
            cursor.execute(paginated_query, params + (pagination.page_size, offset))
            
            items = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            return items, columns, total

    items, columns, total = await asyncio.to_thread(_db_calls)
    
    pages = math.ceil(total / pagination.page_size) if total > 0 else 0
    
    pagination_info = PaginationInfo(
        total=total,
        page=pagination.page,
        page_size=pagination.page_size,
        pages=pages,
        has_next=pagination.page < pages,
        has_prev=pagination.page > 1,
    )
    # Transform property_description to description for consistency
    result = []
    for row in items:
        item_dict = dict(zip(columns, row))
        # Rename property_description to description if it exists
        if 'property_description' in item_dict:
            item_dict['description'] = item_dict.pop('property_description')
        result.append(item_dict)
    return result, pagination_info


# ÈÖçÁΩÆÊó•Âøó - (‰øùÊåÅÊÇ®Áé∞ÊúâÁöÑËØ¶ÁªÜÈÖçÁΩÆ)
# Ensure this basicConfig is called only once, typically at the application entry point.
# If other modules also call basicConfig, it might lead to unexpected behavior.
# For a library/module like server.db, it's better to use logging.getLogger(__name__)
# and let the main application configure the root logger.
# However, since this is main.py, calling it here is usually fine.
if not logging.getLogger().handlers: # Configure only if no handlers are set
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - line %(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )
    logging.getLogger().setLevel(logging.DEBUG)

logger = logging.getLogger(__name__) # Module-specific logger for main.py

logger.info("FastAPIÂ∫îÁî®ÂêØÂä®‰∏≠... Êó•ÂøóÈÖçÁΩÆÂ∑≤ËÆæÁΩÆ‰∏∫DEBUGÁ∫ßÂà´ (Â¶ÇÊûú‰πãÂâçÊú™ÈÖçÁΩÆ)„ÄÇ")

async def check_and_optimize_indexes():
    """
    Ê£ÄÊü•Âπ∂ÂàõÂª∫Êï∞ÊçÆÂ∫ìÊÄßËÉΩ‰ºòÂåñÁ¥¢Âºï
    Âè™ÂàõÂª∫ÊúÄÂÖ≥ÈîÆÁöÑÁ¥¢ÂºïÔºåÈÅøÂÖçÂêØÂä®Êó∂Èó¥ËøáÈïø
    """
    try:
        # ‰ΩøÁî®asyncpgÁõ¥Êé•ËøûÊé•Êï∞ÊçÆÂ∫ì
        import asyncpg
        database_url = os.getenv("DATABASE_URL")
        if not database_url:
            logger.warning("DATABASE_URLÊú™ËÆæÁΩÆÔºåË∑≥ËøáÁ¥¢Âºï‰ºòÂåñ")
            return
            
        conn = await asyncpg.connect(database_url)
        try:
            # Ê£ÄÊü•ÊúÄÂÖ≥ÈîÆÁöÑÂ§çÂêàÁ¥¢ÂºïÊòØÂê¶Â≠òÂú®
            check_sql = """
                SELECT COUNT(*) FROM pg_indexes 
                WHERE tablename = 'properties' 
                AND indexname = 'idx_properties_main_filter'
            """
            result = await conn.fetchval(check_sql)
            
            if result == 0:
                logger.info("Ê£ÄÊµãÂà∞Áº∫Â∞ëÂÖ≥ÈîÆÁ¥¢ÂºïÔºåÂºÄÂßãÂàõÂª∫...")
                
                # ÂàõÂª∫ÊúÄÈáçË¶ÅÁöÑÂ§çÂêàÁ¥¢ÂºïÔºàË¶ÜÁõñ90%ÁöÑÊü•ËØ¢Âú∫ÊôØÔºâ
                # CONCURRENTLY Á°Æ‰øù‰∏çÈîÅË°®
                critical_indexes = [
                    {
                        'name': 'idx_properties_main_filter',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_main_filter 
                            ON properties (suburb, rent_pw, bedrooms, available_date)
                            INCLUDE (address, property_type, bathrooms, parking_spaces, images)
                        """,
                        'description': '‰∏ªÁ≠õÈÄâÂ§çÂêàÁ¥¢Âºï'
                    },
                    {
                        'name': 'idx_properties_available_now',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_available_now 
                            ON properties (listing_id)
                            WHERE available_date IS NULL
                        """,
                        'description': 'Available NowÂø´ÈÄüÊü•ËØ¢'
                    },
                    {
                        'name': 'idx_properties_suburb_lower',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_suburb_lower 
                            ON properties (lower(suburb))
                        """,
                        'description': 'Âå∫Âüü‰∏çÂàÜÂ§ßÂ∞èÂÜôÊêúÁ¥¢'
                    }
                ]
                
                for index in critical_indexes:
                    try:
                        await conn.execute(index['sql'])
                        logger.info(f"‚úÖ ÂàõÂª∫Á¥¢ÂºïÊàêÂäü: {index['name']} - {index['description']}")
                    except Exception as e:
                        # Á¥¢ÂºïÂèØËÉΩÂ∑≤Â≠òÂú®ÊàñÂàõÂª∫Â§±Ë¥•Ôºå‰∏çÂΩ±ÂìçÂêØÂä®
                        logger.debug(f"Á¥¢Âºï {index['name']} ÂàõÂª∫Ë∑≥Ëøá: {e}")
                
                # Êõ¥Êñ∞ÁªüËÆ°‰ø°ÊÅØ
                await conn.execute("ANALYZE properties")
                logger.info("‚úÖ Êï∞ÊçÆÂ∫ìÁ¥¢Âºï‰ºòÂåñÂÆåÊàêÔºåÊü•ËØ¢ÊÄßËÉΩÈ¢ÑËÆ°ÊèêÂçá3-5ÂÄç")
            else:
                logger.info("ÂÖ≥ÈîÆÁ¥¢ÂºïÂ∑≤Â≠òÂú®ÔºåË∑≥Ëøá‰ºòÂåñÊ≠•È™§")
        finally:
            await conn.close()
                
    except Exception as e:
        # Á¥¢Âºï‰ºòÂåñÂ§±Ë¥•‰∏çÂ∫îËØ•ÈòªÊ≠¢Â∫îÁî®ÂêØÂä®
        logger.warning(f"Á¥¢Âºï‰ºòÂåñËøáÁ®ãÂá∫Áé∞ÈîôËØØÔºå‰ΩÜ‰∏çÂΩ±ÂìçÊúçÂä°ÂêØÂä®: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("FastAPI application startup event triggered...")
    await init_db_pool()
    app.state.db_pool_initialized = True
    logger.info("Database pool initialization completed.")
    
    # Ê£ÄÊü•Âπ∂‰ºòÂåñÊï∞ÊçÆÂ∫ìÁ¥¢ÂºïÔºàÂ¢ûÂä†ÂèØË∑≥Ëøá‰∏éË∂ÖÊó∂‰øùÊä§ÔºåÈÅøÂÖçÂêØÂä®Âç°Ê≠ªÔºâ
    # ‰ªÖÂú®Áîü‰∫ßÁéØÂ¢ÉÊâßË°åÔºåÊàñÂΩìÊú™ÊòæÂºèË∑≥ËøáÊó∂ÊâßË°å
    try:
        skip_opt = os.getenv("SKIP_INDEX_OPTIMIZATION", "").lower() in ("1", "true", "yes")
        optimize_timeout = float(os.getenv("INDEX_OPTIMIZE_TIMEOUT", "8"))
        if skip_opt or env != "production":
            logger.info(f"Ë∑≥ËøáÁ¥¢Âºï‰ºòÂåñÔºöSKIP_INDEX_OPTIMIZATION={skip_opt}Ôºåenv={env}")
        else:
            logger.info(f"ÂºÄÂßãÁ¥¢Âºï‰ºòÂåñÔºàË∂ÖÊó∂ {optimize_timeout}sÔºâ...")
            await asyncio.wait_for(check_and_optimize_indexes(), timeout=optimize_timeout)
    except asyncio.TimeoutError:
        logger.warning("Á¥¢Âºï‰ºòÂåñË∂ÖÊó∂ÔºåË∑≥ËøáÂπ∂ÁªßÁª≠ÂêØÂä®„ÄÇ")
    except Exception as e:
        logger.warning(f"Á¥¢Âºï‰ºòÂåñÊ£ÄÊü•Â§±Ë¥•: {e}. ÁªßÁª≠ÂêØÂä®...")
    
    # Initialize Redis Cache with fallback to in-memory cacheÔºàÂ¢ûÂä†ÂèØÈÖçÁΩÆ‰∏éË∂ÖÊó∂Ôºâ
    try:
        redis_url = os.getenv("REDIS_URL", "").strip()
        if not redis_url:
            raise RuntimeError("REDIS_URL Êú™ÈÖçÁΩÆÔºå‰ΩøÁî®ÂÜÖÂ≠òÁºìÂ≠ò")
        connect_timeout = float(os.getenv("REDIS_CONNECT_TIMEOUT", "0.5"))
        socket_timeout = float(os.getenv("REDIS_SOCKET_TIMEOUT", "0.5"))
        ping_timeout = float(os.getenv("REDIS_PING_TIMEOUT", "1.0"))
        redis = aioredis.from_url(
            redis_url,
            encoding="utf8",
            decode_responses=True,
            socket_connect_timeout=connect_timeout,
            socket_timeout=socket_timeout
        )
        # Test Redis connection with timeout
        await asyncio.wait_for(redis.ping(), timeout=ping_timeout)
        app.state.redis = redis  # Store redis client in app state for cache invalidation
        FastAPICache.init(RedisBackend(redis), prefix="fastapi-cache")
        logger.info(f"FastAPI Cache initialized with Redis backend ({redis_url}).")
    except Exception as e:
        logger.warning(f"Redis ‰∏çÂèØÁî®ÊàñÊú™ÈÖçÁΩÆ: {e}„ÄÇ‰ΩøÁî®ÂÜÖÂ≠òÁºìÂ≠ò‰Ωú‰∏∫ÈôçÁ∫ß„ÄÇ")
        # ‰ΩøÁî®ÂÜÖÂ≠òÁºìÂ≠ò‰Ωú‰∏∫ÈôçÁ∫ßÊñπÊ°à
        from fastapi_cache.backends.inmemory import InMemoryBackend
        FastAPICache.init(InMemoryBackend(), prefix="fastapi-cache")
        app.state.redis = None
        logger.info("FastAPI Cache initialized with InMemory backend (fallback).")

    yield
    # Shutdown
    logger.info("FastAPI application shutdown event triggered...")
    await close_db_pool()

# FastAPI Â∫îÁî®ÂÆû‰æã
app = FastAPI(title="Rental MCP Server", version="1.0.0", lifespan=lifespan)
app.state.limiter = limiter

# Ëá™ÂÆö‰πâÁºìÂ≠òÈîÆÔºö‰ΩøÁî®ÂÆåÊï¥URLÔºàÂê´Êü•ËØ¢ÂèÇÊï∞Ôºâ‰Ωú‰∏∫ÁºìÂ≠òÈîÆÔºåÁ°Æ‰øùÂàÜÈ°µ/Á≠õÈÄâÔºàÂ∞§ÂÖ∂ page/page_size„ÄÅ‰ª∑Ê†º/Êó•ÊúüÔºâ‰∏ç‰ºöÁõ∏‰∫íÊ±°Êüì
# ‰∏∫‰ªÄ‰πàÔºöËÆ°Êï∞ËØ∑Ê±ÇÔºàpage_size=1Ôºâ‰∏éÂàóË°®ËØ∑Ê±ÇÔºàpage_size=20ÔºâÂèÇÊï∞‰∏çÂêåÔºåÈªòËÆ§ÈîÆÂèØËÉΩÊú™ÂåÖÂê´Êü•ËØ¢ÔºåÂØºËá¥ÂëΩ‰∏≠Áõ∏ÂêåÁºìÂ≠òÊù°ÁõÆ
from fastapi import Request
def cache_key_by_url(func, namespace, request: Request, response, *args, **kwargs):
    return f"{namespace}:{str(request.url)}"

# Cache helper functions for selective invalidation
async def invalidate_property_cache(property_id: str = None):
    """Invalidate cache for a specific property or all properties"""
    redis = app.state.redis
    if not redis:
        logger.info("Cache invalidation skipped: Redis backend not configured.")
        return
    if property_id:
        # Invalidate specific property detail cache
        pattern = f"fastapi-cache:get_property_by_id:property_id={property_id}*"
    else:
        # Invalidate all property-related caches
        pattern = "fastapi-cache:get_properties*"
    
    async for key in redis.scan_iter(match=pattern):
        await redis.delete(key)
    
    logger.info(f"Cache invalidated for pattern: {pattern}")

async def invalidate_all_cache():
    """Invalidate all cache entries"""
    redis = app.state.redis
    if not redis:
        logger.info("Cache invalidation skipped: Redis backend not configured.")
        return
    async for key in redis.scan_iter(match="fastapi-cache:*"):
        await redis.delete(key)
    logger.info("All cache entries invalidated")

# CORS ‰∏≠Èó¥‰ª∂ÈÖçÁΩÆÔºàÂä®ÊÄÅÂåñÔºâ
# ËØ¥ÊòéÔºà‰∏∫‰ªÄ‰πàËøô‰πàÂÅöÔºâÔºö
# - Áîü‰∫ßÁéØÂ¢É‰ªÖÊîæË°åÊòéÁ°ÆÁöÑÂâçÁ´ØÂüüÂêçÔºàÂÆâÂÖ®‰ºòÂÖàÔºâ
# - ÂºÄÂèë/ÈùûÁîü‰∫ßÁéØÂ¢ÉÊîæÂÆΩÔºà‰ΩøÁî®Ê≠£ÂàôÔºâ‰ª•‰æø‰∫éÊú¨Âú∞Ë∞ÉËØï‰∏é‰∏¥Êó∂ÂüüÂêçÈ™åËØÅ
# - ÂÖÅËÆ∏ÈÄöËøáÁéØÂ¢ÉÂèòÈáè FRONTEND_URL ‰∏é ADDITIONAL_CORS ÈÖçÁΩÆÈ¢ùÂ§ñÊù•Ê∫êÔºàÈÄóÂè∑ÂàÜÈöîÔºâ
env = os.getenv("ENVIRONMENT", "development").lower()
frontend_url = os.getenv("FRONTEND_URL", "").strip()
additional_cors = os.getenv("ADDITIONAL_CORS", "").strip()

# Êî∂ÈõÜÂÖÅËÆ∏ÁöÑÊù•Ê∫êÔºàÁîü‰∫ß‰ΩøÁî®Ôºâ
allowed_origins = {
    # Â∏∏ËßÅÊú¨Âú∞Êù•Ê∫êÔºàÁî®‰∫éÁîü‰∫ßÊó∂‰πüÂèØ‰øùÁïô‰ª•‰æø‰∏¥Êó∂ËÅîË∞ÉÔºâ
    "http://localhost",
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "http://localhost:5500",
    "http://127.0.0.1:5500",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
    "http://localhost:8888",
    "http://127.0.0.1:8888",
}

if frontend_url:
    allowed_origins.add(frontend_url)

if additional_cors:
    for origin in [x.strip() for x in additional_cors.split(",") if x.strip()]:
        allowed_origins.add(origin)

if env == "production" and allowed_origins:
    # Áîü‰∫ßÔºöÁôΩÂêçÂçïÊòéÁ°ÆÂüüÂêçÔºõ‰øùÊåÅ allow_credentials=True
    app.add_middleware(
        CORSMiddleware,
        allow_origins=list(allowed_origins),
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
else:
    # ÂºÄÂèë/ÈùûÁîü‰∫ßÔºö‰ΩøÁî®Ê≠£ÂàôÂÖÅËÆ∏‰ªªÊÑèÊù•Ê∫êÔºå‰æø‰∫éÊú¨Âú∞‰∏é‰∏¥Êó∂ÂÖ¨ÁΩëÂüüË∞ÉËØï
    # ËØ¥ÊòéÔºö‰ΩøÁî® allow_origin_regex ÂèØ‰∏é allow_credentials=True ÂÖ±Â≠òÔºåÂπ∂ÂõûÊòæÂÖ∑‰Ωì Origin
    app.add_middleware(
        CORSMiddleware,
        allow_origin_regex=".*",
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Exception Handlers
@app.exception_handler(RateLimitExceeded)
async def rate_limit_exceeded_handler(request: Request, exc: RateLimitExceeded):
    return error_response(
        code=ErrorCodes.RATE_LIMIT_EXCEEDED,
        message=f"Rate limit exceeded: {exc.detail}",
        status_code=status.HTTP_429_TOO_MANY_REQUESTS
    )

@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    if exc.status_code == 404:
        code = ErrorCodes.RESOURCE_NOT_FOUND
    elif exc.status_code == 401:
        code = ErrorCodes.AUTHENTICATION_ERROR
    elif exc.status_code == 403:
        code = ErrorCodes.AUTHORIZATION_ERROR
    # Note: Rate limit (429) would be handled by its own library if used
    else:
        code = ErrorCodes.BAD_REQUEST
    
    return error_response(code=code, message=exc.detail, status_code=exc.status_code)

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    return error_response(
        code=ErrorCodes.VALIDATION_ERROR,
        message="Input validation failed",
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        details={"errors": exc.errors()}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"An unhandled exception occurred: {exc}", exc_info=True)
    return error_response(
        code=ErrorCodes.INTERNAL_SERVER_ERROR,
        message="An internal server error occurred.",
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
    )


# Ëá™ÂÆö‰πâ GraphQL ‰∏ä‰∏ãÊñáËé∑ÂèñÂô®
async def get_graphql_context(request: Request, db_conn: Any = Depends(get_db_conn_dependency)) -> Dict[str, Any]:
    """
    Custom context getter for GraphQL.
    Injects the database connection from the pool into the GraphQL context.
    `Depends(get_db_conn_dependency)` uses FastAPI's dependency injection.
    """
    logger.info(f"DEBUG: Type of db_conn in get_graphql_context: {type(db_conn)}") # Debug print
    # logger.debug(f"GraphQL context: db_conn type: {type(db_conn)}, id: {id(db_conn)}")
    return {
        "request": request,
        "sync_db_conn": db_conn, # The connection from the pool via get_db_conn_dependency
        # Add other context variables if needed
    }

# --- Directions Endpoint Logic ---

class TravelMode(str, Enum):
    DRIVING = "DRIVING"
    WALKING = "WALKING"
    BICYCLING = "BICYCLING"
    TRANSIT = "TRANSIT"

class DirectionsRequest(BaseModel):
    origin: str = Query(..., description="Ëµ∑ÁÇπÂùêÊ†á 'lat,lng'")
    destination: str = Query(..., description="ÁõÆÁöÑÂú∞Âú∞ÂùÄÊàñÂùêÊ†á")
    mode: TravelMode = Query(TravelMode.DRIVING, description="Âá∫Ë°åÊñπÂºè")

@app.get("/api/directions", tags=["Services"])
@limiter.limit("30/minute")
async def get_directions(request: Request, params: DirectionsRequest = Depends()):
    """
    Ëé∑Âèñ‰∏§‰∏™Âú∞ÁÇπ‰πãÈó¥ÁöÑÈÄöÂã§Êó∂Èó¥ÂíåË∑ùÁ¶ª„ÄÇ
    """
    api_key = os.getenv("GOOGLE_MAPS_API_KEY")
    if not api_key:
        logger.error("GOOGLE_MAPS_API_KEY not set in environment.")
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Server configuration error.",
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

    url = "https://maps.googleapis.com/maps/api/directions/json"
    request_params = {
        "origin": params.origin,
        "destination": params.destination,
        "mode": params.mode.value.lower(),
        "key": api_key
    }

    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url, params=request_params)
            response.raise_for_status()  # Will raise an exception for 4XX/5XX responses
            data = response.json()

            if data["status"] != "OK":
                logger.warning(f"Google Maps API Warn: {data['status']} - {data.get('error_message', '')}")
                return success_response(data={"duration": "N/A", "distance": "N/A", "error": data.get('status', 'No results')})

            route = data["routes"][0]
            leg = route["legs"][0]
            
            return success_response(data={
                "duration": leg["duration"]["text"],
                "distance": leg["distance"]["text"]
            })

        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error calling Google Maps API: {e.response.status_code} - {e.response.text}")
            return error_response(
                code="EXTERNAL_API_ERROR",
                message="Failed to fetch directions from external service.",
                status_code=status.HTTP_502_BAD_GATEWAY
            )
        except Exception as e:
            logger.error(f"An unexpected error occurred while fetching directions: {e}", exc_info=True)
            return error_response(
                code=ErrorCodes.INTERNAL_SERVER_ERROR,
                message="An internal error occurred.",
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


# ÂàõÂª∫ GraphQL Ë∑ØÁî±Âô®ÔºåÂπ∂‰ΩøÁî®Ëá™ÂÆö‰πâ‰∏ä‰∏ãÊñá
graphql_app_router = GraphQLRouter(
    gql_schema, # Use the imported schema
    context_getter=get_graphql_context, # Pass our custom context getter
    graphql_ide="graphiql" # Enable GraphiQL interface
)
# Include routers
app.include_router(auth_router, tags=["Authentication"])
app.include_router(graphql_app_router, prefix="/graphql", tags=["GraphQL"])


@app.get("/", tags=["Root"])
async def root():
    """Root endpoint providing basic server status."""
    return {"message": "Rental MCP Server is running. Access GraphQL at /graphql"}

@app.get("/api/health", tags=["Debug"])
async def health_check():
    """A simple health check endpoint."""
    logger.info("Health check endpoint was called.")
    return {"status": "ok"}

@app.post("/api/cache/invalidate", tags=["Cache Management"])
async def invalidate_cache(
    property_id: Optional[str] = None,
    invalidate_all: bool = False
):
    """
    Invalidate cache selectively.
    - If property_id is provided, invalidate cache for that specific property
    - If invalidate_all is True, invalidate all cache entries
    - Otherwise, invalidate all property-related caches
    """
    try:
        if invalidate_all:
            await invalidate_all_cache()
            return {"status": "success", "message": "All cache entries invalidated"}
        else:
            await invalidate_property_cache(property_id)
            if property_id:
                return {"status": "success", "message": f"Cache invalidated for property {property_id}"}
            else:
                return {"status": "success", "message": "All property caches invalidated"}
    except Exception as e:
        logger.error(f"Failed to invalidate cache: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/cache/stats", tags=["Cache Management"])
async def get_cache_stats():
    """Get cache statistics"""
    try:
        redis = app.state.redis
        if not redis:
            return {
                "backend": "memory",
                "total_keys": 0,
                "property_list_cached": 0,
                "property_details_cached": 0,
                "memory_used": "N/A",
                "connected_clients": 0
            }
        info = await redis.info()
        keys_count = await redis.dbsize()
        
        # Count cache entries by pattern
        property_list_count = 0
        property_detail_count = 0
        
        async for key in redis.scan_iter(match="fastapi-cache:get_properties*"):
            property_list_count += 1
        
        async for key in redis.scan_iter(match="fastapi-cache:get_property_by_id*"):
            property_detail_count += 1
        
        return {
            "total_keys": keys_count,
            "property_list_cached": property_list_count,
            "property_details_cached": property_detail_count,
            "memory_used": info.get("used_memory_human", "N/A"),
            "connected_clients": info.get("connected_clients", 0)
        }
    except Exception as e:
        logger.error(f"Failed to get cache stats: {e}")
        return {"status": "error", "message": str(e)}

# Optional: Test endpoint for DB connection
@app.get("/test_db_connection", tags=["Debug"])
async def test_db(db: Any = Depends(get_db_conn_dependency)): # Kept async as it was
    """
    Temporarily modified to return the type of the injected 'db' object
    and check for 'cursor' attribute for debugging purposes.
    """
    # logger.info(f"DEBUG: Type of db in test_db: {type(db)}") # This log will be superseded by the response
    return {
        "status": "ok",
        "db_type": str(type(db)),
        "has_cursor": hasattr(db, "cursor")
    }

@app.get("/api/auth/test", tags=["Authentication"])
async def test_auth_system(db: Any = Depends(get_db_conn_dependency)):
    """Test endpoint to verify authentication system is working"""
    try:
        from crud.auth_crud import AuthCRUD
        
        # Test database tables exist
        with db.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM information_schema.tables WHERE table_name IN ('users', 'user_addresses')")
            table_count = cursor.fetchone()[0]
        
        # Initialize tables if they don't exist
        if table_count < 2:
            AuthCRUD.init_auth_tables(db)
            
        return {
            "status": "ok", 
            "message": "Authentication system is ready",
            "tables_initialized": True,
            "endpoints_available": [
                "/api/auth/register",
                "/api/auth/login", 
                "/api/auth/verify-email",
                "/api/auth/refresh",
                "/api/auth/me",
                "/api/auth/addresses"
            ]
        }
    except Exception as e:
        logger.error(f"Auth test error: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/email/test", tags=["Email"])
async def test_email_service():
    """Test email service configuration"""
    try:
        from services.email_service import test_email_service
        result = await test_email_service()
        return result
    except Exception as e:
        logger.error(f"Email test error: {e}")
        return {"status": "error", "message": str(e)}

@app.post("/api/email/test-send", tags=["Email"])
async def test_send_email(
    email: str = "test@example.com",
    name: str = "Test User"
):
    """Test sending a verification email (development only)"""
    try:
        from services.email_service import send_verification_email
        from config.email_config import get_email_config
        
        config = get_email_config()
        if not config.development_mode:
            return {"status": "error", "message": "Test email sending only available in development mode"}
        
        # Generate a test token
        import secrets
        test_token = secrets.token_urlsafe(32)
        
        success = await send_verification_email(email, name, test_token)
        
        return {
            "status": "success" if success else "error",
            "message": "Test email sent successfully" if success else "Failed to send test email",
            "email": email,
            "development_mode": config.development_mode,
            "test_token": test_token[:8] + "..." if success else None
        }
    except Exception as e:
        logger.error(f"Test send email error: {e}")
        return {"status": "error", "message": str(e)}

# ============== AIËÅäÂ§©Á≥ªÁªü ==============

# PydanticÊ®°ÂûãÂÆö‰πâ
class ChatMessage(BaseModel):
    role: str  # 'user', 'assistant', 'agent'
    content: str
    timestamp: Optional[str] = None
    agent_type: Optional[str] = None  # 'general', 'property', 'legal', 'contract', 'service'

class ChatRequest(BaseModel):
    message: str
    conversation_id: str
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    message: str
    agent_type: str
    cards: Optional[List[Dict[str, Any]]] = None
    suggestions: Optional[List[str]] = None

class PropertyCard(BaseModel):
    listing_id: int
    image: str
    price: int
    address: str
    commute: str
    bedrooms: str
    bathrooms: int
    features: List[str]

class ServiceCard(BaseModel):
    type: str
    title: str
    description: str
    price: str
    features: Optional[List[str]] = None
    action: str

# AIËÅäÂ§©ÊúçÂä°Á±ª
class ChatService:
    def __init__(self):
        self.conversations = {}  # Â≠òÂÇ®‰ºöËØù‰∏ä‰∏ãÊñá
        
    def route_to_agent(self, message: str) -> str:
        """Êô∫ËÉΩË∑ØÁî±Âà∞ÂêàÈÄÇÁöÑAgent"""
        msg = message.lower()
        
        # ÊàøÊ∫êÊêúÁ¥¢Áõ∏ÂÖ≥
        if any(keyword in msg for keyword in ['ÊàøÊ∫ê', 'ÊàøÂ≠ê', 'ÁßüÊàø', 'uts', 'unsw', 'usyd', 'ÈÄöÂã§', 'Ë∑ùÁ¶ª']):
            return 'property'
        
        # Ê≥ïÂæãÂí®ËØ¢Áõ∏ÂÖ≥
        if any(keyword in msg for keyword in ['Ê≥ïÂæã', 'ÊùÉÁõä', 'ÊäºÈáë', 'Êàø‰∏ú', 'ÁßüÂÆ¢', 'ËøùÁ∫¶']):
            return 'legal'
        
        # ÂêàÂêåÂÆ°Ê†∏Áõ∏ÂÖ≥
        if any(keyword in msg for keyword in ['ÂêàÂêå', 'Êù°Ê¨æ', 'Á≠æÁ∫¶', 'ÂçèËÆÆ', 'ÂÆ°Ê†∏']):
            return 'contract'
        
        # ÊúçÂä°Áõ∏ÂÖ≥
        if any(keyword in msg for keyword in ['‰ª£ÁúãÊàø', 'Êê¨ÂÆ∂', 'Âí®ËØ¢', 'È¢ÑÁ∫¶', 'ÊúçÂä°']):
            return 'service'
        
        return 'general'
    
    async def process_message(self, request: ChatRequest, db_conn: Any) -> ChatResponse:
        """Â§ÑÁêÜËÅäÂ§©Ê∂àÊÅØ"""
        message = request.message
        conversation_id = request.conversation_id
        
        # Ë∑ØÁî±Âà∞ÂêàÈÄÇÁöÑAgent
        agent_type = self.route_to_agent(message)
        
        # Ê†πÊçÆAgentÁ±ªÂûãÂ§ÑÁêÜÊ∂àÊÅØ
        if agent_type == 'property':
            return await self.handle_property_query(message, db_conn)
        elif agent_type == 'legal':
            return await self.handle_legal_query(message)
        elif agent_type == 'contract':
            return await self.handle_contract_query(message)
        elif agent_type == 'service':
            return await self.handle_service_query(message)
        else:
            return await self.handle_general_query(message)
    
    async def handle_property_query(self, message: str, db_conn: Any) -> ChatResponse:
        """Â§ÑÁêÜÊàøÊ∫êÊü•ËØ¢"""
        msg = message.lower()
        
        # Ê£ÄÊü•ÊòØÂê¶ËØ¢ÈóÆÂ§ßÂ≠¶Áõ∏ÂÖ≥
        universities = ['uts', 'unsw', 'usyd', 'macquarie', 'ÊÇâÂ∞ºÁßëÊäÄÂ§ßÂ≠¶', 'Êñ∞ÂçóÂ®ÅÂ∞îÂ£´Â§ßÂ≠¶', 'ÊÇâÂ∞ºÂ§ßÂ≠¶']
        mentioned_uni = None
        for uni in universities:
            if uni in msg:
                mentioned_uni = uni
                break
        
        if mentioned_uni:
            uni_name = self.get_university_name(mentioned_uni)
            response_text = f"Â•ΩÁöÑÔºÅÊàëÊù•‰∏∫ÊÇ®Êé®Ëçê{uni_name}ÈôÑËøëÁöÑÊàøÊ∫ê„ÄÇ"
            
            # Ê®°ÊãüÊàøÊ∫êÊï∞ÊçÆÔºàÂÆûÈôÖÂ∫îËØ•‰ªéÊï∞ÊçÆÂ∫ìÊü•ËØ¢Ôºâ
            property_cards = [
                {
                    "id": 1,
                    "image": "https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?w=300&h=200&fit=crop",
                    "price": 776,
                    "address": "Central Park Student Village",
                    "commute": "UTSÊ≠•Ë°å8ÂàÜÈíü",
                    "bedrooms": "Studio",
                    "bathrooms": 1,
                    "features": ["Á©∫Ë∞É", "Ê¥óË°£Êú∫", "È´òÈÄüÁΩëÁªú"]
                },
                {
                    "id": 2,
                    "image": "https://images.unsplash.com/photo-1564013799919-ab600027ffc6?w=300&h=200&fit=crop",
                    "price": 706,
                    "address": "Redfern Student Accommodation",
                    "commute": "UTSËΩªËΩ®10ÂàÜÈíü",
                    "bedrooms": "Studio",
                    "bathrooms": 1,
                    "features": ["ÂÅ•Ë∫´Êàø", "ÂÅúËΩ¶‰Ωç", "ÂÆâ‰øù"]
                }
            ]
            
            return ChatResponse(
                message=response_text,
                agent_type="property",
                cards=property_cards,
                suggestions=["Êü•ÁúãÊõ¥Â§öÊàøÊ∫ê", "È¢ÑÁ∫¶‰ª£ÁúãÊàø", "‰∫ÜËß£ÈÄöÂã§ËØ¶ÊÉÖ"]
            )
        else:
            return ChatResponse(
                message="ÊàëÊù•Â∏ÆÊÇ®ÊâæÊàøÊ∫êÔºÅËØ∑ÂëäËØâÊàëÊÇ®ÁöÑÈúÄÊ±ÇÔºö\n\n‚Ä¢ ÊÇ®Âú®Âì™ÊâÄÂ§ßÂ≠¶‰∏äÂ≠¶Ôºü\n‚Ä¢ È¢ÑÁÆóËåÉÂõ¥ÊòØÂ§öÂ∞ëÔºü\n‚Ä¢ ÂÅèÂ•ΩÁöÑÂå∫ÂüüÊàñ‰∫§ÈÄöÊñπÂºèÔºü",
                agent_type="property",
                suggestions=["UTSÈôÑËøëÊàøÊ∫ê", "UNSWÈôÑËøëÊàøÊ∫ê", "USYDÈôÑËøëÊàøÊ∫ê", "È¢ÑÁÆó$500-800"]
            )
    
    async def handle_legal_query(self, message: str) -> ChatResponse:
        """Â§ÑÁêÜÊ≥ïÂæãÂí®ËØ¢"""
        msg = message.lower()
        
        if 'ÊäºÈáë' in msg:
            response = """ÂÖ≥‰∫éÊäºÈáëÁöÑÊ≥ïÂæãËßÑÂÆöÔºö

**ÊäºÈáëÊ†áÂáÜ**Ôºö
‚Ä¢ ‰∏ÄËà¨‰∏çË∂ÖËøá4Âë®ÁßüÈáë
‚Ä¢ ÂøÖÈ°ªÂ≠òÂÖ•ÊîøÂ∫úÁõëÁÆ°Ë¥¶Êà∑
‚Ä¢ ‰∏çËÉΩÁî®‰ΩúÊúÄÂêé‰∏ÄÊúüÁßüÈáë

**ÈÄÄËøòÊù°‰ª∂**Ôºö
‚Ä¢ ÊàøÂ±ãÊó†ÊçüÂùèÔºöÂÖ®È¢ùÈÄÄËøò
‚Ä¢ ÊúâÊçüÂùèÔºöÊâ£Èô§Áª¥‰øÆË¥πÂêéÈÄÄËøò
‚Ä¢ 14Â§©ÂÜÖÂøÖÈ°ªÂ§ÑÁêÜ

**Êàë‰ª¨ÁöÑÂª∫ËÆÆ**Ôºö
Á≠æÁ∫¶Êó∂ÊãçÁÖßËÆ∞ÂΩïÊàøÂ±ãÁä∂ÊÄÅÔºåÊê¨Âá∫Êó∂‰πüË¶ÅÊãçÁÖßÂØπÊØî„ÄÇ"""
        elif 'Êàø‰∏ú' in msg or 'ÊùÉÁõä' in msg:
            response = """Êæ≥Ê¥≤ÁßüÂÆ¢ÊùÉÁõä‰øùÊä§Ôºö

**Êàø‰∏ú‰∏çËÉΩ**Ôºö
‚Ä¢ ÈöèÊÑèËøõÂÖ•ÊÇ®ÁöÑÊàøÈó¥
‚Ä¢ Êó†ÁêÜÁî±È©±Ëµ∂ÁßüÂÆ¢
‚Ä¢ Ê≠ßËßÜÊÄßÂØπÂæÖ

**ÊÇ®ÁöÑÊùÉÂà©**Ôºö
‚Ä¢ ÂÆâÈùô‰∫´Áî®ÊùÉ
‚Ä¢ Áª¥‰øÆË¶ÅÊ±ÇÊùÉ
‚Ä¢ ÈöêÁßÅ‰øùÊä§ÊùÉ

**ÈúÄË¶ÅÂ∏ÆÂä©Êó∂**Ôºö
‚Ä¢ ËÅîÁ≥ªÂΩìÂú∞ÁßüÂÆ¢Âçè‰ºö
‚Ä¢ Áî≥ËØ∑‰ª≤Ë£ÅÊúçÂä°
‚Ä¢ ÂØªÊ±ÇÊ≥ïÂæãÊè¥Âä©"""
        else:
            response = """ÊàëÊòØÊÇ®ÁöÑÁßüËµÅÊ≥ïÂæãÈ°æÈóÆÔºÅÊàëÂèØ‰ª•Â∏ÆÊÇ®Ëß£Á≠îÔºö

‚Ä¢ ÁßüÊàøÂêàÂêåÊù°Ê¨æËß£Èáä
‚Ä¢ ÊäºÈáëÂíåÁßüÈáëÁõ∏ÂÖ≥Ê≥ïËßÑ
‚Ä¢ ÁßüÂÆ¢ÊùÉÁõä‰øùÊä§
‚Ä¢ Êàø‰∏úË¥£‰ªª‰πâÂä°
‚Ä¢ ËøùÁ∫¶ÂíåÁ∫†Á∫∑Â§ÑÁêÜ

ËØ∑ÂÖ∑‰ΩìÂëäËØâÊàëÊÇ®ÈÅáÂà∞ÁöÑÈóÆÈ¢òÔºü"""
        
        service_card = {
            "type": "legal",
            "title": "‚öñÔ∏è ‰∏ì‰∏öÊ≥ïÂæãÂí®ËØ¢",
            "description": "Â§çÊùÇÊ°à‰æã‰∫∫Â∑•Ê≥ïÂæãÈ°æÈóÆ",
            "price": "$99",
            "features": ["30ÂàÜÈíü‰∏ì‰∏öÂí®ËØ¢", "‰π¶Èù¢ÊÑèËßÅ‰π¶", "‰∏≠ÊñáÂÖ®Á®ãÊúçÂä°"],
            "action": "È¢ÑÁ∫¶Âí®ËØ¢"
        }
        
        return ChatResponse(
            message=response,
            agent_type="legal",
            cards=[service_card],
            suggestions=["ÊäºÈáëÈóÆÈ¢ò", "Êàø‰∏úÁ∫†Á∫∑", "ÂêàÂêåÊù°Ê¨æ", "È¢ÑÁ∫¶Ê≥ïÂæãÂí®ËØ¢"]
        )
    
    async def handle_contract_query(self, message: str) -> ChatResponse:
        """Â§ÑÁêÜÂêàÂêåÂÆ°Ê†∏"""
        response = """ÊàëÂèØ‰ª•Â∏ÆÊÇ®ÂÆ°Ê†∏ÁßüÊàøÂêàÂêåÔºÅ

**AIÂø´ÈÄüÂÆ°Ê†∏**Ôºö
‚Ä¢ 30ÁßíËØÜÂà´ÂÖ≥ÈîÆÊù°Ê¨æ
‚Ä¢ Ê†áÊ≥®ÊΩúÂú®È£éÈô©ÁÇπ
‚Ä¢ Êèê‰æõ‰øÆÊîπÂª∫ËÆÆ
‚Ä¢ ÁîüÊàêÂÆ°Ê†∏Êä•Âëä

**Â∏∏ËßÅÈ£éÈô©Êù°Ê¨æ**Ôºö
‚Ä¢ ËøáÈ´òÁöÑËøùÁ∫¶Èáë
‚Ä¢ ‰∏çÂêàÁêÜÁöÑÁª¥‰øÆË¥£‰ªª
‚Ä¢ Ê®°Á≥äÁöÑÊäºÈáëÊù°Ê¨æ
‚Ä¢ ÈôêÂà∂ÊÄß‰ΩøÁî®ËßÑÂÆö

‰∏ä‰º†ÊÇ®ÁöÑÂêàÂêåÔºåÊàëÊù•‰∏∫ÊÇ®ËØ¶ÁªÜÂàÜÊûêÔºÅ"""
        
        service_card = {
            "type": "contract",
            "title": "üìã AIÂêàÂêåÂÆ°Ê†∏",
            "description": "Êô∫ËÉΩËØÜÂà´È£éÈô©Êù°Ê¨æ",
            "price": "$25",
            "features": ["30ÁßíÂø´ÈÄüÂàÜÊûê", "È£éÈô©ÁÇπÊ†áÊ≥®", "‰øÆÊîπÂª∫ËÆÆ", "‰∏ì‰∏öÊä•Âëä"],
            "action": "‰∏ä‰º†ÂêàÂêå"
        }
        
        return ChatResponse(
            message=response,
            agent_type="contract",
            cards=[service_card],
            suggestions=["‰∏ä‰º†ÂêàÂêå", "Â∏∏ËßÅÊù°Ê¨æËØ¥Êòé", "È£éÈô©Ê°à‰æã", "Ê≥ïÂæãÂª∫ËÆÆ"]
        )
    
    async def handle_service_query(self, message: str) -> ChatResponse:
        """Â§ÑÁêÜÊúçÂä°Êü•ËØ¢"""
        msg = message.lower()
        
        if '‰ª£ÁúãÊàø' in msg:
            response = "ÊàëÊù•‰∏∫ÊÇ®‰ªãÁªç‰ª£ÁúãÊàøÊúçÂä°ÔºÅËøôÊòØÊàë‰ª¨ÊúÄÂèóÊ¨¢ËøéÁöÑÊúçÂä°„ÄÇ"
            
            service_card = {
                "type": "inspection",
                "title": "üè† ‰∏ì‰∏ö‰ª£ÁúãÊàøÊúçÂä°",
                "description": "‰∏ì‰∏öÈ°æÈóÆÂÆûÂú∞ÁúãÊàøÊãçÊëÑ",
                "price": "$35",
                "features": ["‰∏ì‰∏öÊãçÊëÑÂΩïÂÉè", "ËØ¶ÁªÜËØÑ‰º∞Êä•Âëä", "2Â∞èÊó∂ÂÜÖÂÆåÊàê", "ÂæÆ‰ø°ÂÆûÊó∂Ê≤üÈÄö"],
                "action": "Á´ãÂç≥È¢ÑÁ∫¶"
            }
            
            return ChatResponse(
                message=response,
                agent_type="service",
                cards=[service_card],
                suggestions=["È¢ÑÁ∫¶‰ª£ÁúãÊàø", "Êü•ÁúãÊúçÂä°ËØ¶ÊÉÖ", "‰ª∑Ê†ºËØ¥Êòé", "ÊúçÂä°ÊµÅÁ®ã"]
            )
        else:
            response = "Êàë‰ª¨Êèê‰æõÂÖ®Êñπ‰ΩçÁöÑÁßüÊàøÊúçÂä°ÔºÅ"
            
            service_cards = [
                {
                    "type": "inspection",
                    "title": "üè† ‰ª£ÁúãÊàøÊúçÂä°",
                    "description": "‰∏ì‰∏öÂÆûÂú∞ÁúãÊàøÂΩïÂÉè",
                    "price": "$35",
                    "action": "Á´ãÂç≥È¢ÑÁ∫¶"
                },
                {
                    "type": "moving",
                    "title": "üöö Â≠¶ÁîüÊê¨ÂÆ∂",
                    "description": "Â∞è‰ª∂Áâ©ÂìÅÊê¨Ëøê",
                    "price": "$89Ëµ∑",
                    "action": "Ëé∑ÂèñÊä•‰ª∑"
                },
                {
                    "type": "consultation",
                    "title": "üíº Á≠æÁ∫¶Èô™Âêå",
                    "description": "‰∏≠ÊñáÂÖ®Á®ãÈô™Âêå",
                    "price": "$59",
                    "action": "È¢ÑÁ∫¶ÊúçÂä°"
                }
            ]
            
            return ChatResponse(
                message=response,
                agent_type="service",
                cards=service_cards,
                suggestions=["‰ª£ÁúãÊàøÊúçÂä°", "Êê¨ÂÆ∂ÊúçÂä°", "Á≠æÁ∫¶Èô™Âêå", "ÂÖ®Â•óÊúçÂä°ÂåÖ"]
            )
    
    async def handle_general_query(self, message: str) -> ChatResponse:
        """Â§ÑÁêÜÈÄöÁî®Êü•ËØ¢"""
        msg = message.lower()
        
        if '‰Ω†Â•Ω' in msg or 'hello' in msg:
            response = "ÊÇ®Â•ΩÔºÅÂæàÈ´òÂÖ¥‰∏∫ÊÇ®ÊúçÂä° üòä ÊàëÊòØÊÇ®ÁöÑ‰∏ìÂ±ûÁßüÊàøÂä©ÊâãÔºåÂèØ‰ª•Â∏ÆÊÇ®ÊâæÊàøÊ∫ê„ÄÅÂÆâÊéíÁúãÊàø„ÄÅËß£Á≠îÊ≥ïÂæãÈóÆÈ¢ò„ÄÇÊÇ®ÊÉ≥‰∫ÜËß£‰ªÄ‰πàÔºü"
        elif '‰ª∑Ê†º' in msg or 'Â§öÂ∞ëÈí±' in msg:
            response = """Êàë‰ª¨ÁöÑÊúçÂä°‰ª∑Ê†ºÈÄèÊòéÂÖ¨ÂºÄÔºö

üè† **‰ª£ÁúãÊàøÊúçÂä°**: $35/Ê¨°
üìã **ÂêàÂêåÂÆ°Ê†∏**: $25/‰ªΩ  
‚öñÔ∏è **Ê≥ïÂæãÂí®ËØ¢**: $99/Ê¨°
üöö **Êê¨ÂÆ∂ÊúçÂä°**: $89Ëµ∑
üíº **Á≠æÁ∫¶Èô™Âêå**: $59/Ê¨°

ÊâÄÊúâÊúçÂä°ÈÉΩÊòØ‰∏ÄÊ¨°ÊÄßÊî∂Ë¥πÔºåÊó†ÈöêËóèË¥πÁî®ÔºÅÈúÄË¶Å‰∫ÜËß£ÂÖ∑‰ΩìÂì™È°πÊúçÂä°Ôºü"""
        elif 'Â§ßÂ≠¶' in msg or 'Â≠¶Ê†°' in msg:
            response = """Êàë‰ª¨‰∏ªË¶ÅÊúçÂä°Ëøô‰∫õÂ§ßÂ≠¶ÁöÑÂ≠¶ÁîüÔºö

üè´ **ÊÇâÂ∞ºÁßëÊäÄÂ§ßÂ≠¶** (UTS)
üè´ **Êñ∞ÂçóÂ®ÅÂ∞îÂ£´Â§ßÂ≠¶** (UNSW)  
üè´ **ÊÇâÂ∞ºÂ§ßÂ≠¶** (USYD)
üè´ **È∫¶ËÄÉÁëûÂ§ßÂ≠¶** (Macquarie)

ËØ∑ÂëäËØâÊàëÊÇ®Âú®Âì™ÊâÄÂ§ßÂ≠¶ÔºåÊàëÊù•‰∏∫ÊÇ®Êé®ËçêÈôÑËøëÁöÑ‰ºòË¥®ÊàøÊ∫êÔºÅ"""
        else:
            response = """ÊàëÁêÜËß£ÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ‰Ωú‰∏∫‰∏ì‰∏öÁöÑÁßüÊàøÂä©ÊâãÔºåÊàëÂèØ‰ª•Â∏ÆÊÇ®Ôºö

üîç **Êô∫ËÉΩÊâæÊàø**: Ê†πÊçÆÂ§ßÂ≠¶Êé®ËçêÊàøÊ∫ê
üè† **‰ª£ÁúãÊàøÊúçÂä°**: $35‰∏ì‰∏öÂÆûÂú∞ÁúãÊàø  
üìã **ÂêàÂêåÂÆ°Ê†∏**: AIÂø´ÈÄüËØÜÂà´È£éÈô©Êù°Ê¨æ
‚öñÔ∏è **Ê≥ïÂæãÂí®ËØ¢**: ‰∏ì‰∏öÁßüÊàøÊ≥ïÂæãÂª∫ËÆÆ
üöö **ÈÖçÂ•óÊúçÂä°**: Êê¨ÂÆ∂„ÄÅÁ≠æÁ∫¶Èô™ÂêåÁ≠â

ÊÇ®ÊúÄÊÉ≥‰∫ÜËß£Âì™ÊñπÈù¢Ôºü"""
        
        return ChatResponse(
            message=response,
            agent_type="general",
            suggestions=["ÊâæÊàøÊ∫ê", "‰ª£ÁúãÊàøÊúçÂä°", "Ê≥ïÂæãÂí®ËØ¢", "‰ª∑Ê†ºËØ¥Êòé"]
        )
    
    def get_university_name(self, uni_code: str) -> str:
        """Ëé∑ÂèñÂ§ßÂ≠¶‰∏≠ÊñáÂêçÁß∞"""
        names = {
            'uts': 'ÊÇâÂ∞ºÁßëÊäÄÂ§ßÂ≠¶',
            'unsw': 'Êñ∞ÂçóÂ®ÅÂ∞îÂ£´Â§ßÂ≠¶', 
            'usyd': 'ÊÇâÂ∞ºÂ§ßÂ≠¶',
            'macquarie': 'È∫¶ËÄÉÁëûÂ§ßÂ≠¶',
            'ÊÇâÂ∞ºÁßëÊäÄÂ§ßÂ≠¶': 'ÊÇâÂ∞ºÁßëÊäÄÂ§ßÂ≠¶',
            'Êñ∞ÂçóÂ®ÅÂ∞îÂ£´Â§ßÂ≠¶': 'Êñ∞ÂçóÂ®ÅÂ∞îÂ£´Â§ßÂ≠¶',
            'ÊÇâÂ∞ºÂ§ßÂ≠¶': 'ÊÇâÂ∞ºÂ§ßÂ≠¶'
        }
        return names.get(uni_code.lower(), uni_code)

# ÂàõÂª∫ËÅäÂ§©ÊúçÂä°ÂÆû‰æã
chat_service = ChatService()

# AIËÅäÂ§©APIÁ´ØÁÇπ
@app.post("/api/chat", response_model=ChatResponse, tags=["AI Chat"])
async def chat_endpoint(request: ChatRequest, db_conn: Any = Depends(get_db_conn_dependency)):
    """AIËÅäÂ§©APIÁ´ØÁÇπ"""
    try:
        logger.info(f"Êî∂Âà∞ËÅäÂ§©ËØ∑Ê±Ç: {request.message}")
        response = await chat_service.process_message(request, db_conn)
        logger.info(f"ËÅäÂ§©ÂìçÂ∫î: {response.message[:100]}...")
        return response
    except Exception as e:
        logger.error(f"ËÅäÂ§©Â§ÑÁêÜÈîôËØØ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ËÅäÂ§©Â§ÑÁêÜÂ§±Ë¥•: {str(e)}")

# Note: Ensure that `server.api.graphql_schema.py` uses `info.context.get('sync_db_conn')`
# to retrieve the database connection in its resolvers.
# The `get_db_session` context manager will handle returning the connection to the pool.

# --- Celery Task Endpoints ---
from celery_config import celery_app
from tasks import debug_task, example_db_task
from celery.result import AsyncResult

@app.post("/api/tasks/debug", status_code=status.HTTP_202_ACCEPTED, tags=["Tasks"])
async def start_debug_task(api_key: str = Security(get_api_key)):
    """Endpoint to trigger the simple debug task."""
    try:
        logger.info("Attempting to queue debug_task...")
        task = debug_task.delay()
        logger.info(f"Task {task.id} queued successfully.")
        return success_response(data={"task_id": task.id, "message": "Debug task started"})
    except Exception as e:
        logger.error(f"Failed to queue debug_task: {e}", exc_info=True)
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Failed to queue task.",
            status_code=500
        )

@app.post("/api/tasks/db", status_code=status.HTTP_202_ACCEPTED, tags=["Tasks"])
async def start_db_task(api_key: str = Security(get_api_key)):
    """Endpoint to trigger the example database task."""
    try:
        logger.info("Attempting to queue example_db_task...")
        # Pass some example data to the task
        task = example_db_task.delay("Hello from FastAPI endpoint!")
        logger.info(f"Task {task.id} queued successfully.")
        return success_response(data={"task_id": task.id, "message": "Database task started"})
    except Exception as e:
        logger.error(f"Failed to queue db_task: {e}", exc_info=True)
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Failed to queue task.",
            status_code=500
        )

@app.get("/api/tasks/{task_id}", tags=["Tasks"], response_model=APIResponse)
async def get_task_status(task_id: str, api_key: str = Security(get_api_key)):
    """Endpoint to check the status of a Celery task."""
    task_result = AsyncResult(task_id, app=celery_app)
    
    response_data = {
        "task_id": task_id,
        "status": task_result.status,
        "result": task_result.result if task_result.ready() else None,
    }

    if task_result.failed():
        return error_response(
            code="TASK_FAILED",
            message="The task failed to execute.",
            status_code=500,
            details=response_data
        )
        
    return success_response(data=response_data)
# --- End Celery Task Endpoints ---

from crud.properties_crud import get_property_by_id_from_db

@app.get("/api/properties/{property_id}", tags=["Properties"], response_model=APIResponse[Dict])
@cache(expire=1800)  # Cache for 30 minutes
async def get_property_by_id(property_id: str, db: Any = Depends(get_db_conn_dependency)):
    """
    Get a single property by its ID.
    """
    logger.info(f"====== HIT get_property_by_id with ID: {property_id} ======")
    def _static_fallback(db_unavailable: bool):
        fallback = static_data_utils.get_property(property_id)
        if fallback:
            return success_response(data=fallback)
        if db_unavailable and not static_data_utils.dataset_available():
            return error_response(
                code=ErrorCodes.INTERNAL_SERVER_ERROR,
                message="Property data source is temporarily unavailable.",
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            )
        return error_response(
            code=ErrorCodes.RESOURCE_NOT_FOUND,
            message=f"Property with ID {property_id} not found.",
            status_code=status.HTTP_404_NOT_FOUND,
        )

    if db is None:
        logger.warning("Database connection unavailable for property detail; using fallback data")
        return _static_fallback(db_unavailable=True)

    try:
        prop = await asyncio.to_thread(get_property_by_id_from_db, property_id)
    except RuntimeError as exc:
        logger.error(f"Database runtime error while fetching property {property_id}: {exc}")
        return _static_fallback(db_unavailable=True)
    except Exception as exc:
        logger.error(f"Unexpected error fetching property {property_id}: {exc}", exc_info=True)
        return _static_fallback(db_unavailable=True)

    if not prop:
        return _static_fallback(db_unavailable=False)

    # Manually convert the Strawberry object to a dictionary
    prop_dict = {
        "listing_id": prop.listing_id,
        "address": prop.address,
        "suburb": prop.suburb,
        "rent_pw": prop.rent_pw,
        "bedrooms": prop.bedrooms,
        "bathrooms": prop.bathrooms,
        "property_type": prop.property_type,
        "property_url": prop.property_url,
        "postcode": prop.postcode,
        "bond": prop.bond,
        "parking_spaces": prop.parking_spaces,
        "available_date": prop.available_date,
        "images": prop.images,
        "property_features": prop.property_features,
        "latitude": prop.latitude,
        "longitude": prop.longitude,
        "geom_wkt": prop.geom_wkt,
        "is_furnished": prop.is_furnished,
        "description": prop.description,  # Add description field
        "property_headline": prop.property_headline,  # Ê∑ªÂä†ÊàøÊ∫êÊ†áÈ¢òÂ≠óÊÆµ
        "inspection_times": prop.inspection_times  # Ë°•ÂÖÖÁúãÊàøÊó∂Èó¥Â≠óÊÆµÔºå‰øÆÂ§çÂà∑Êñ∞ÂêéÊ∂àÂ§±
    }

    return success_response(data=prop_dict)


@app.get("/api/properties", tags=["Properties"], response_model=APIResponse[List[Dict]])
@cache(expire=900, key_builder=cache_key_by_url)  # Cache for 15 minutesÔºàÂåÖÂê´URLÊü•ËØ¢ÂèÇÊï∞Âà∞ÁºìÂ≠òÈîÆÔºâ
async def get_properties(
    request: Request,
    pagination: PaginationParams = Depends(), 
    db: Any = Depends(get_db_conn_dependency),
    # Filter parameters
    suburb: Optional[str] = None,
    property_type: Optional[str] = None,
    bedrooms: Optional[str] = None,  # Can be comma-separated like "1,2,3"
    bathrooms: Optional[str] = None,  # Can be comma-separated like "1,2"
    parking: Optional[str] = None,  # Can be comma-separated like "0,1,2"
    minPrice: Optional[int] = None,
    maxPrice: Optional[int] = None,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None,
    isFurnished: Optional[bool] = None,
    # ÂÖºÂÆπÂèÇÊï∞ÔºàV2/ÈÉ®ÂàÜÂÖ•Âè£ÔºâÔºöÂ¶Ç‰º†ÂÖ• furnished=trueÔºåÂàôÁ≠â‰ª∑‰∫é isFurnished=true
    furnished: Optional[bool] = None,
    # ÁÇπÂêçËøáÊª§Ôºà‰æø‰∫éÊ†°È™åÔºâ
    listing_id: Optional[str] = None,
    # ÊéíÂ∫èÂèÇÊï∞ÔºàÁôΩÂêçÂçïÔºâÔºöprice_asc/available_date_asc/suburb_az/inspection_earliest
    sort: Optional[str] = None,
):
    """
    Get a paginated list of properties with optional filters.
    Supports both page-based and cursor-based pagination.
    """
    # --- BE-002: Êü•ËØ¢ÂèÇÊï∞ÁôΩÂêçÂçïÊ†°È™åÔºàÈò≤Ê≥®ÂÖ•/Â•ëÁ∫¶‰∏ÄËá¥Ôºâ ---
    # ‰∏≠ÊñáÊ≥®ÈáäÔºöÂú®‰∏çÊîπÂèòÁé∞ÊúâÈîÆËØ≠‰πâÁöÑÂâçÊèê‰∏ãÊã¶Êà™Êú™Áü•ÈîÆÔºåÂπ∂ÂØπÁôΩÂêçÂçïÊéíÂ∫èÂÄºÂÅö‰∏•Ê†ºÊ†°È™å
    try:
        # ÂÖÅËÆ∏ÁöÑÊü•ËØ¢ÈîÆÔºàV1 Â•ëÁ∫¶Ôºå‰øùÊåÅ‰∏éÂâçÁ´ØÁé∞Áä∂‰∏ÄËá¥Ôºâ
        allowed_keys = {
            "suburb", "property_type", "bedrooms", "bathrooms", "parking",
            "minPrice", "maxPrice", "date_from", "date_to",
            "isFurnished", "furnished",
            "listing_id",
            "page", "page_size", "cursor", "sort",
            # ÂÆπÈîôÔºöpostcodes Âú®ÊóßÂâçÁ´Ø‰∏≠ÂèØËÉΩÂá∫Áé∞ÔºåÁªü‰∏ÄÂú®Êò†Â∞ÑÂ±ÇÁßªÈô§ÔºåËøôÈáå‰ªÖÊîæË°å‰ª•ÈÅøÂÖç 400
            "postcodes",
        }
        qp_keys = set(request.query_params.keys())
        unknown_keys = sorted(list(qp_keys - allowed_keys))
        invalid_values = {}

        # ÊéíÂ∫èÂÄºÁôΩÂêçÂçïÔºöÂÖ∂‰ΩôÂÄº‰∏ÄÂæã 400ÔºåÂÖúÂ∫ïÊéíÂ∫èÂú®ÂêéÁª≠‰ªç‰∏∫ listing_id ASC
        allowed_sorts = {"price_asc", "available_date_asc", "suburb_az", "inspection_earliest"}
        if "sort" in request.query_params:
            s_raw = (request.query_params.get("sort") or "").strip().lower()
            if s_raw and s_raw not in allowed_sorts:
                invalid_values["sort"] = {"got": s_raw, "allowed": sorted(list(allowed_sorts))}

        if unknown_keys or invalid_values:
            return error_response(
                code=ErrorCodes.BAD_REQUEST,
                message="Invalid query parameters",
                status_code=status.HTTP_400_BAD_REQUEST,
                details={
                    "unknown_keys": unknown_keys or None,
                    "allowed_keys": sorted(list(allowed_keys)),
                    "invalid_values": invalid_values or None,
                }
            )
    except Exception as _be002_e:
        # ÂÆπÈîôÔºöÁôΩÂêçÂçïÊ†°È™åÂºÇÂ∏∏‰∏çÂ∫îÈòªÊñ≠Ê≠£Â∏∏Êü•ËØ¢ÔºåËÆ∞ÂΩïÊó•ÂøóÂêéÁªßÁª≠
        logger.warning(f"Whitelist validation failed but skipped: {_be002_e}")

    def _static_properties_response():
        params_copy = dict(request.query_params)
        params_copy.pop("cursor", None)
        params_copy.setdefault("page", pagination.page)
        params_copy.setdefault("page_size", pagination.page_size)
        fallback = static_data_utils.list_properties(
            params_copy,
            page=pagination.page,
            page_size=pagination.page_size,
        )
        if fallback is None:
            return error_response(
                code=ErrorCodes.INTERNAL_SERVER_ERROR,
                message="Property list is temporarily unavailable.",
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            )
        pagination_info = PaginationInfo(**fallback["pagination"])
        return success_response(data=fallback["data"], pagination=pagination_info)

    if db is None:
        logger.warning("Database unavailable for property list; using static fallback")
        return _static_properties_response()

    # Build the base query with filters - Âè™ÈÄâÊã©ÂàóË°®È°µÈúÄË¶ÅÁöÑÂ≠óÊÆµÔºåÂáèÂ∞ëÊï∞ÊçÆ‰º†Ëæì
    # ÊéíÈô§Â§ßÂ≠óÊÆµÂ¶Ç description Âíå property_featuresÔºåÊèêÂçáÊÄßËÉΩ
    base_query = """SELECT 
        listing_id, property_url, address, suburb, state, postcode, 
        property_type, rent_pw, bond, bedrooms, bathrooms, parking_spaces,
        available_date, inspection_times, agency_name, agent_name,
        property_headline, latitude, longitude, images,
        is_active, status, created_at, last_updated,
        has_air_conditioning, is_furnished, has_balcony, has_dishwasher,
        has_laundry, has_parking, has_pool, has_gym
    FROM properties"""
    count_query = "SELECT COUNT(*) FROM properties"
    
    # Build WHERE clause conditions
    conditions = []
    params = []
    
    # ÂßãÁªàÂè™ËøîÂõûÊ¥ªË∑ÉÁöÑÊàøÊ∫êÔºàÂÖ≥ÈîÆ‰øÆÂ§çÔºöËøáÊª§Â∑≤‰∏ãÊû∂ÊàøÊ∫êÔºâ
    conditions.append("is_active = TRUE")
    
    # ÊåáÂÆö listing_id Êó∂ÂÅöÁÇπÂêçËøáÊª§Ôºà‰æø‰∫éÊ†°È™å/Â§çÁé∞ÂçïÊù°Ôºâ
    if listing_id:
        try:
            lid = int(listing_id)
            conditions.append("listing_id = %s")
            params.append(lid)
        except (ValueError, TypeError):
            # ÂøΩÁï•ÈùûÊ≥ï idÔºå‰∏çÂΩ±ÂìçÂÖ∂‰ªñÊù°‰ª∂
            pass

    # Add suburb filter - support multiple suburbs (comma-separated)
    if suburb:
        suburbs = [s.strip() for s in suburb.split(',') if s and s.strip()]
        if suburbs:
            # ÂéªÈáç‰ª•ÈÅøÂÖçÈáçÂ§çÂç†‰ΩçÁ¨¶ÔºåÂπ∂‰ΩøÁî® lower(suburb) ÂëΩ‰∏≠ÂáΩÊï∞Á¥¢Âºï
            unique_suburbs = list(dict.fromkeys(suburbs))
            placeholders = ','.join(['%s'] * len(unique_suburbs))
            conditions.append(f"LOWER(suburb) IN ({placeholders})")
            params.extend([s.lower() for s in unique_suburbs])

    # Add property type filter
    if property_type:
        conditions.append("property_type ILIKE %s")
        params.append(f"%{property_type}%")
    
    # Add bedrooms filter (handle comma-separated values)
    if bedrooms:
        bedroom_values = bedrooms.split(',')
        bedroom_conditions = []
        bedroom_params: List[int] = []
        for value in bedroom_values:
            value = value.strip()
            if value == '4+':
                bedroom_conditions.append("bedrooms >= %s")
                bedroom_params.append(4)
            elif value.isdigit():
                bedroom_conditions.append("bedrooms = %s")
                bedroom_params.append(int(value))
        if bedroom_conditions:
            conditions.append(f"({' OR '.join(bedroom_conditions)})")
            params.extend(bedroom_params)
    
    # Add bathrooms filter (handle comma-separated values)
    if bathrooms:
        bathroom_values = bathrooms.split(',')
        bathroom_conditions = []
        bathroom_params: List[int] = []
        for value in bathroom_values:
            value = value.strip()
            if value == '3+':
                bathroom_conditions.append("bathrooms >= %s")
                bathroom_params.append(3)
            elif value.isdigit():
                bathroom_conditions.append("bathrooms = %s")
                bathroom_params.append(int(value))
        if bathroom_conditions:
            conditions.append(f"({' OR '.join(bathroom_conditions)})")
            params.extend(bathroom_params)
    
    # Add parking filter (handle comma-separated values)
    if parking:
        parking_values = [v.strip() for v in parking.split(',') if v and v.strip()]
        parking_conditions: List[str] = []
        parking_params: List[int] = []
        for value in parking_values:
            if value.endswith('+') and value[:-1].isdigit():
                parking_conditions.append("parking_spaces >= %s")
                parking_params.append(int(value[:-1]))
            elif value.isdigit():
                parking_conditions.append("parking_spaces = %s")
                parking_params.append(int(value))
        if parking_conditions:
            conditions.append(f"({' OR '.join(parking_conditions)})")
            params.extend(parking_params)
    
    # Add price range filters
    if minPrice is not None:
        conditions.append("rent_pw >= %s")
        params.append(minPrice)
    
    if maxPrice is not None:
        conditions.append("rent_pw <= %s")
        params.append(maxPrice)
    
    # Add date filters
    # Â§ÑÁêÜÁ©∫Âá∫Êó•ÊúüÁ≠õÈÄâÈÄªËæëÔºö
    # - NULLË°®Á§∫"Available now"ÔºàÁ´ãÂç≥ÂèØÂÖ•‰ΩèÔºâ
    # - date_fromÂà∞date_toÔºöÁ≠õÈÄâÂú®Ëøô‰∏™Êó∂Èó¥ÊÆµÂÜÖÁ©∫Âá∫ÁöÑÊàøÊ∫ê
    # - Â¶ÇÊûúÊó∂Èó¥ÊÆµÂåÖÂê´‰ªäÂ§©ÊàñËøáÂéªÔºåNULLÔºàAvailable nowÔºâÂ∫îËØ•Ë¢´ÂåÖÂê´
    from datetime import datetime
    today = datetime.now().date()
    
    if date_from and date_to:
        # Áî®Êà∑ÈÄâÊã©‰∫ÜÊó∂Èó¥ËåÉÂõ¥ÔºöÊâæÂú®Ëøô‰∏™Êó∂Èó¥ÊÆµÂÜÖÁ©∫Âá∫ÁöÑÊàøÊ∫ê
        # Â¶ÇÊûúdate_from <= ‰ªäÂ§©ÔºåÂåÖÂê´Available nowÁöÑÊàøÊ∫ê
        if datetime.strptime(date_from, '%Y-%m-%d').date() <= today:
            conditions.append(
                "(available_date IS NULL OR (available_date >= %s AND available_date <= %s))"
            )
        else:
            # Êú™Êù•ÁöÑÊó∂Èó¥ÊÆµÔºå‰∏çÂåÖÂê´Available now
            conditions.append(
                "(available_date >= %s AND available_date <= %s)"
            )
        params.append(date_from)
        params.append(date_to)
    elif date_from:
        # Âè™ÊúâÂºÄÂßãÊó•ÊúüÔºöÊâæ‰ªéËøô‰∏™Êó•Êúü‰πãÂêéÁ©∫Âá∫ÁöÑÊàøÊ∫ê
        if datetime.strptime(date_from, '%Y-%m-%d').date() <= today:
            conditions.append(
                "(available_date IS NULL OR available_date >= %s)"
            )
        else:
            conditions.append("available_date >= %s")
        params.append(date_from)
    elif date_to:
        # Âè™ÊúâÁªìÊùüÊó•ÊúüÔºöÊâæÂú®Ëøô‰∏™Êó•Êúü‰πãÂâçÁ©∫Âá∫ÁöÑÊàøÊ∫ê
        conditions.append(
            "(available_date IS NULL OR available_date <= %s)"
        )
        params.append(date_to)
    
    # ÂÆ∂ÂÖ∑Á≠õÈÄâÔºàÂÖºÂÆπ isFurnished ‰∏é furnished ‰∏§‰∏™ÈîÆÔºõ‰ªÖÂΩìÊòæÂºè‰∏∫ true/false Êó∂ÊâçÁ≠õÔºâ
    # ËØ¥ÊòéÔºöÂ∞Ü is_furnished Áªü‰∏ÄËΩ¨‰∏∫ÊñáÊú¨ÂêéÂÅöÈõÜÂêàÂåπÈÖçÔºåÈÅøÂÖçÂéÜÂè≤ text/‰∏âÊÄÅÂØºËá¥ÁöÑ 500Ôºõ‰∏ç‰ºöÊää 'unknown' ÂΩì true/false
    effectiveFurnished = isFurnished if isFurnished is not None else furnished
    if effectiveFurnished is not None:
        if effectiveFurnished:
            conditions.append("NULLIF(TRIM(LOWER(is_furnished::text)), '') IN ('t','true','yes','1')")
        else:
            conditions.append("NULLIF(TRIM(LOWER(is_furnished::text)), '') IN ('f','false','no','0')")
    
    # Build WHERE clause
    where_clause = ""
    if conditions:
        where_clause = " WHERE " + " AND ".join(conditions)
    
    # Update queries with WHERE clause
    base_query += where_clause
    count_query += where_clause

    # ÊéíÂ∫èÊò†Â∞ÑÔºà‰∏∫‰ªÄ‰πàÔºöËÆ©ÂâçÁ´Ø Sort ÁúüÊ≠£ÁîüÊïàÔºõ‰ªÖÂÖÅËÆ∏ÁôΩÂêçÂçïÔºåÈò≤Ê≥®ÂÖ•ÔºõÂπ∂ÈôÑÂä† listing_id ASC ‰Ωú‰∏∫Á®≥ÂÆöÊ¨°Â∫èÈîÆÔºâ
    order_clause = " ORDER BY listing_id ASC"
    if sort:
        s = str(sort).strip().lower()
        if s == "price_asc":
            order_clause = " ORDER BY rent_pw ASC NULLS LAST, listing_id ASC"
        elif s == "available_date_asc":
            order_clause = " ORDER BY available_date ASC NULLS FIRST, listing_id ASC"
        elif s == "suburb_az":
            order_clause = " ORDER BY lower(suburb) ASC NULLS LAST, listing_id ASC"
        elif s == "inspection_earliest":
            # TODOÔºöP1 Á≤æÁ°ÆËß£Êûê inspection_times ÁöÑ‚ÄúÊúÄÊó©ÁúãÊàøÊó∂Èó¥‚ÄùËøõË°åÊéíÂ∫è
            # ÂΩìÂâçÂÖà‰∏é available_date_asc Á≠â‰ª∑ÔºåÊª°Ë∂≥ P0 ÁúüÊ≠£ÁîüÊïàÁöÑÂâçÁ´ØË°®Áé∞
            order_clause = " ORDER BY available_date ASC NULLS FIRST, listing_id ASC"
    
    
    # Simple cursor implementation based on listing_id
    # A more robust implementation would handle sorting
    if pagination.cursor:
        try:
            cursor_val = int(decode_cursor(pagination.cursor))
            # Add cursor condition to existing WHERE clause
            if where_clause:
                query = f"{base_query} AND listing_id > %s ORDER BY listing_id ASC"
            else:
                query = f"{base_query} WHERE listing_id > %s ORDER BY listing_id ASC"
            # Append cursor value to existing params
            cursor_params = params + [cursor_val]
        except (ValueError, TypeError):
            raise HTTPException(status_code=400, detail="Invalid cursor")

        def _db_call_cursor():
            with db.cursor() as cur:
                # Fetch one more than page_size to check for has_next
                cur.execute(f"{query} LIMIT %s", cursor_params + [pagination.page_size + 1])
                items = cur.fetchall()
                columns = [desc[0] for desc in cur.description]
                return items, columns
        
        try:
            items, columns = await asyncio.to_thread(_db_call_cursor)
        except Exception as exc:
            logger.error(f"Cursor pagination query failed: {exc}", exc_info=True)
            return _static_properties_response()

        has_next = len(items) > pagination.page_size
        if has_next:
            items = items[:-1] # remove extra item
        
        items_as_dicts = []
        for row in items:
            item_dict = dict(zip(columns, row))
            # Rename property_description to description if it exists
            if 'property_description' in item_dict:
                item_dict['description'] = item_dict.pop('property_description')
            items_as_dicts.append(item_dict)
        next_cursor = encode_cursor(items_as_dicts[-1]['listing_id']) if items_as_dicts and has_next else None

        pagination_info = PaginationInfo(
            total=-1, # Cursor pagination doesn't usually return total
            page=1, # Page number is not relevant for cursor
            page_size=pagination.page_size,
            pages=-1,
            has_next=has_next,
            has_prev=pagination.cursor is not None,
            next_cursor=next_cursor
        )
        return success_response(data=items_as_dicts, pagination=pagination_info)
    else:
        # Page-based pagination
        query = f"{base_query}{order_clause}"
        try:
            items, pagination_info = await paginate_query(db, query, count_query, tuple(params), pagination)
        except Exception as exc:
            logger.error(f"Page-based pagination query failed: {exc}", exc_info=True)
            return _static_properties_response()
        return success_response(data=items, pagination=pagination_info)


# ========================================
# Location/Search Suggestions API
# ========================================

@app.get("/api/locations/suggestions", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_location_suggestions(
    q: Optional[str] = Query(None, description="Search query"),
    limit: int = Query(20, ge=1, le=100),
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get location suggestions for search autocomplete.
    Returns suburbs and postcodes with property counts.
    """
    def _static_suggestions():
        suggestions = static_data_utils.suggest_locations(q, limit)
        return success_response(data=suggestions)

    try:
        if db is None:
            logger.warning("Database unavailable for location suggestions; using fallback data")
            return _static_suggestions()

        if q and len(q.strip()) > 0:
            # Search with query
            search_term = q.strip().lower()
            
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as clean_postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL
                AND is_active = TRUE
                AND (
                    LOWER(suburb) LIKE %s
                    OR REPLACE(postcode, '.0', '') LIKE %s
                )
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY 
                CASE 
                    WHEN LOWER(suburb) = %s THEN 1
                    WHEN LOWER(suburb) LIKE %s THEN 2
                    ELSE 3
                END,
                property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (
                        f'%{search_term}%',
                        f'{search_term}%',
                        search_term,
                        f'{search_term}%',
                        limit
                    ))
                    results = cur.fetchall()
                    return results
            
            try:
                results = await asyncio.to_thread(_db_call)
            except Exception as exc:
                logger.error(f"Location suggestions query failed: {exc}", exc_info=True)
                return _static_suggestions()
            
            # Format results
            suggestions = []
            for row in results:
                suburb = row[0]
                postcode = row[1]
                count = row[2]
                
                suggestions.append({
                    "id": f"{suburb}_{postcode}",
                    "type": "suburb",
                    "name": suburb,
                    "postcode": postcode,
                    "fullName": f"{suburb}, NSW, {postcode}",
                    "count": count
                })
            
            return success_response(data=suggestions)
        
        else:
            # No query - return all locations
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (limit,))
                    results = cur.fetchall()
                    return results
            
            try:
                results = await asyncio.to_thread(_db_call)
            except Exception as exc:
                logger.error(f"Location suggestions query failed: {exc}", exc_info=True)
                return _static_suggestions()
            
            # Format results
            suggestions = []
            for row in results:
                suburb = row[0]
                postcode = row[1]
                count = row[2]
                
                suggestions.append({
                    "id": f"{suburb}_{postcode}",
                    "type": "suburb",
                    "name": suburb,
                    "postcode": postcode,
                    "fullName": f"{suburb}, NSW, {postcode}",
                    "count": count
                })
            
            return success_response(data=suggestions)
            
    except Exception as e:
        logger.error(f"Error getting location suggestions: {str(e)}", exc_info=True)
        return _static_suggestions()


@app.get("/api/locations/all", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_all_locations(
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get all unique locations with property counts.
    Used for initializing search suggestions.
    """
    def _static_locations():
        locations = static_data_utils.list_locations()
        return success_response(data=locations)

    if db is None:
        logger.warning("Database unavailable for all locations; using fallback data")
        return _static_locations()

    try:
        query = """
        SELECT
            suburb,
            REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
            COUNT(DISTINCT listing_id) as property_count
        FROM properties
        WHERE suburb IS NOT NULL
          AND is_active = TRUE
        GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
        ORDER BY property_count DESC
        """
        
        def _db_call():
            with db.cursor() as cur:
                cur.execute(query)
                results = cur.fetchall()
                return results
        
        try:
            results = await asyncio.to_thread(_db_call)
        except Exception as exc:
            logger.error(f"Location list query failed: {exc}", exc_info=True)
            return _static_locations()
        
        # Format results for both suburb and postcode lookups
        locations = []
        postcode_map = {}
        
        for row in results:
            suburb = row[0]
            postcode = row[1]
            count = row[2]
            
            # Add suburb entry
            locations.append({
                "id": f"{suburb}_{postcode}",
                "type": "suburb",
                "name": suburb,
                "postcode": postcode,
                "fullName": f"{suburb}, NSW, {postcode}",
                "count": count
            })
            
            # Aggregate by postcode
            if postcode not in postcode_map:
                postcode_map[postcode] = {
                    "id": f"postcode_{postcode}",
                    "type": "postcode",
                    "name": postcode,
                    "suburbs": [],
                    "fullName": f"{postcode}",
                    "count": 0
                }
            postcode_map[postcode]["suburbs"].append(suburb)
            postcode_map[postcode]["count"] += count
        
        # Update postcode fullNames with suburb list
        for postcode_data in postcode_map.values():
            suburbs_str = ", ".join(postcode_data["suburbs"][:3])  # Show first 3 suburbs
            if len(postcode_data["suburbs"]) > 3:
                suburbs_str += f" +{len(postcode_data['suburbs']) - 3} more"
            postcode_data["fullName"] = f"{postcode_data['name']} ({suburbs_str})"
            locations.append(postcode_data)
        
        # Sort by count
        locations.sort(key=lambda x: x["count"], reverse=True)
        
        return success_response(data=locations)
        
    except Exception as e:
        logger.error(f"Error getting all locations: {str(e)}", exc_info=True)
        return _static_locations()


@app.get("/api/locations/nearby", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_nearby_suburbs(
    suburb: str = Query(..., description="Suburb name"),
    limit: int = Query(6, ge=1, le=20),
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get nearby suburbs based on the selected suburb.
    Returns suggested suburbs that users might also be interested in.
    """
    # Define nearby suburbs mapping (Sydney area)
    nearby_mapping = {
        "Sydney": ["Haymarket", "Surry Hills", "Pyrmont", "Ultimo", "The Rocks", "Darling Harbour"],
        "Ultimo": ["Sydney", "Chippendale", "Pyrmont", "Glebe", "Surry Hills", "Camperdown"],
        "Chippendale": ["Ultimo", "Redfern", "Darlington", "Glebe", "Newtown", "Camperdown"],
        "Surry Hills": ["Sydney", "Darlinghurst", "Paddington", "Redfern", "Moore Park", "Elizabeth Bay"],
        "Redfern": ["Chippendale", "Surry Hills", "Waterloo", "Alexandria", "Eveleigh", "Darlington"],
        "Newtown": ["Erskineville", "Enmore", "Stanmore", "Camperdown", "Marrickville", "St Peters"],
        "Glebe": ["Ultimo", "Forest Lodge", "Annandale", "Camperdown", "Leichhardt", "Pyrmont"],
        "Pyrmont": ["Sydney", "Ultimo", "Glebe", "Balmain", "Rozelle", "Barangaroo"],
        "Waterloo": ["Redfern", "Alexandria", "Zetland", "Rosebery", "Surry Hills", "Moore Park"],
        "Alexandria": ["Waterloo", "Redfern", "Erskineville", "Beaconsfield", "Rosebery", "Mascot"],
        "Zetland": ["Waterloo", "Rosebery", "Kensington", "Alexandria", "Beaconsfield", "Green Square"],
        "Rosebery": ["Zetland", "Waterloo", "Alexandria", "Mascot", "Beaconsfield", "Eastlakes"],
        "Mascot": ["Rosebery", "Alexandria", "Botany", "Eastlakes", "Pagewood", "Wolli Creek"],
        "Randwick": ["Kensington", "Kingsford", "Coogee", "Clovelly", "Centennial Park", "Queens Park"],
        "Kensington": ["Randwick", "Kingsford", "Zetland", "Centennial Park", "Moore Park", "Rosebery"],
        "Kingsford": ["Randwick", "Kensington", "Maroubra", "Daceyville", "Eastlakes", "Coogee"],
        "Maroubra": ["Kingsford", "Pagewood", "Hillsdale", "Malabar", "Coogee", "South Coogee"],
        "Hurstville": ["Penshurst", "Allawah", "Mortdale", "Beverley Park", "Peakhurst", "Oatley"],
        "Burwood": ["Strathfield", "Croydon", "Ashfield", "Five Dock", "Concord", "Homebush"],
        "Campsie": ["Canterbury", "Belmore", "Lakemba", "Ashbury", "Clemton Park", "Earlwood"],
        "Parramatta": ["Westmead", "Harris Park", "North Parramatta", "Rosehill", "Granville", "Rydalmere"],
        "Chatswood": ["Artarmon", "Willoughby", "Lane Cove", "Roseville", "Lindfield", "North Willoughby"],
        "North Sydney": ["Milsons Point", "Kirribilli", "Neutral Bay", "Waverton", "McMahons Point", "Crows Nest"],
        "Bondi": ["Bondi Beach", "North Bondi", "Tamarama", "Bellevue Hill", "Waverley", "Bondi Junction"],
        "Coogee": ["Randwick", "South Coogee", "Clovelly", "Maroubra", "Kingsford", "Bronte"]
    }

    def _static_nearby():
        nearby_data = static_data_utils.nearby_suburbs(suburb, limit, mapping=nearby_mapping)
        return success_response(data=nearby_data)

    try:
        if db is None:
            logger.warning("Database unavailable for nearby suburbs; using fallback data")
            return _static_nearby()

        # Get nearby suburbs from mapping
        nearby_suburbs = nearby_mapping.get(suburb, [])[:limit]

        if not nearby_suburbs:
            # If no mapping found, return popular suburbs as fallback
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL AND suburb != %s
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (suburb, limit))
                    results = cur.fetchall()
                    return results
            
            try:
                results = await asyncio.to_thread(_db_call)
            except Exception as exc:
                logger.error(f"Nearby suburb fallback query failed: {exc}", exc_info=True)
                return _static_nearby()
        else:
            # Get data for nearby suburbs
            placeholders = ','.join(['%s'] * len(nearby_suburbs))
            query = f"""
            SELECT
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IN ({placeholders})
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, nearby_suburbs)
                    results = cur.fetchall()
                    return results
            
            try:
                results = await asyncio.to_thread(_db_call)
            except Exception as exc:
                logger.error(f"Nearby suburb query failed: {exc}", exc_info=True)
                return _static_nearby()
        
        # Format results
        suggestions = []
        for row in results:
            suburb_name = row[0]
            postcode = row[1]
            count = row[2]
            
            suggestions.append({
                "id": f"{suburb_name}_{postcode}",
                "type": "suburb",
                "name": suburb_name,
                "postcode": postcode,
                "fullName": f"{suburb_name}, NSW, {postcode}",
                "count": count
            })
        
        return success_response(data={
            "current": suburb,
            "nearby": suggestions
        })
        
    except Exception as e:
        logger.error(f"Error getting nearby suburbs: {str(e)}", exc_info=True)
        return _static_nearby()
