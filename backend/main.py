from fastapi import FastAPI, Request, Depends, HTTPException, Query, status, Security
from fastapi.security import APIKeyHeader, OAuth2PasswordBearer
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from fastapi.middleware.cors import CORSMiddleware
from strawberry.fastapi import GraphQLRouter
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend
from fastapi_cache.decorator import cache
from fastapi_cache.coder import JsonCoder
from redis import asyncio as aioredis
from pydantic import BaseModel, Field, validator
from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from jose import JWTError, jwt
from datetime import datetime, timedelta, date
# import os # os and load_dotenv are now handled in server.db
import logging
from typing import Any, Dict, List, Optional, TypeVar, Generic, Tuple
import json
import asyncio
import os
from contextlib import asynccontextmanager
import math
import base64
import httpx
from enum import Enum

# ä»æˆ‘ä»¬çš„æ¨¡å—å¯¼å…¥
from api.graphql_schema import schema as gql_schema # Renamed to avoid conflict with strawberry.Schema
from api.auth_routes import router as auth_router # Import auth routes
import db as db_module # Import the module itself
from db import init_db_pool, close_db_pool, get_db_conn_dependency # Import specific functions

# Standardized API Response Models
T = TypeVar('T')

class PaginationInfo(BaseModel):
    total: int
    page: int = 1
    page_size: int = 20
    pages: int
    has_next: bool
    has_prev: bool
    next_cursor: Optional[str] = None

class ErrorInfo(BaseModel):
    code: str
    message: str
    details: Optional[Dict[str, Any]] = None

class APIResponse(BaseModel, Generic[T]):
    status: str = "success"
    data: Optional[T] = None
    pagination: Optional[PaginationInfo] = None
    error: Optional[ErrorInfo] = None

# Response Factory Functions
def success_response(data: Any = None, pagination: Optional[PaginationInfo] = None) -> Dict[str, Any]:
    return APIResponse(status="success", data=data, pagination=pagination).dict()

def error_response(code: str, message: str, status_code: int, details: Optional[Dict[str, Any]] = None) -> JSONResponse:
    return JSONResponse(
        status_code=status_code,
        content=APIResponse(status="error", error=ErrorInfo(code=code, message=message, details=details)).dict(exclude_none=True)
    )

# Error Codes
class ErrorCodes:
    VALIDATION_ERROR = "VALIDATION_ERROR"
    AUTHENTICATION_ERROR = "AUTHENTICATION_ERROR"
    AUTHORIZATION_ERROR = "AUTHORIZATION_ERROR"
    RESOURCE_NOT_FOUND = "RESOURCE_NOT_FOUND"
    RATE_LIMIT_EXCEEDED = "RATE_LIMIT_EXCEEDED"
    INTERNAL_SERVER_ERROR = "INTERNAL_SERVER_ERROR"
    BAD_REQUEST = "BAD_REQUEST"

# --- Security Configurations ---

# API Key Authentication
API_KEY = os.getenv("API_KEY", "your_default_dev_api_key") # Get API Key from environment
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

async def get_api_key(api_key_header: str = Security(api_key_header)):
    if api_key_header is None:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="API key is missing")
    if api_key_header != API_KEY:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Invalid API Key")
    return api_key_header

# Rate Limiting
limiter = Limiter(key_func=get_remote_address)

# JWT Authentication
SECRET_KEY = os.getenv("SECRET_KEY", "a_very_secret_key_for_development")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/token") # Placeholder token URL

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# Placeholder for user model and DB interaction
class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None

async def get_user(username: str):
    # This is a placeholder. In a real app, you'd query the database.
    if username == "johndoe":
        return User(username="johndoe", email="johndoe@example.com", full_name="John Doe")
    return None

async def get_current_user(token: str = Depends(oauth2_scheme)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    user = await get_user(username=username)
    if user is None:
        raise credentials_exception
    return user

# Input Validation Model
class PropertyCreate(BaseModel):
    title: str = Field(..., min_length=3, max_length=100)
    description: str = Field(..., min_length=10)
    price: float = Field(..., gt=0)
    bedrooms: int = Field(..., ge=0)
    available_from: date
    
    @validator('title')
    def title_must_be_valid(cls, v):
        if '<script>' in v.lower():
            raise ValueError('Title cannot contain script tags')
        return v
    
    @validator('price')
    def price_must_be_reasonable(cls, v):
        if v > 10000000: # Set a reasonable max price
            raise ValueError('Price is out of reasonable range')
        return v

# --- End Security Configurations ---


# Pydantic Models for Pagination
class PaginationParams:
    def __init__(
        self,
        page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
        page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µé¡¹ç›®æ•°"),
        cursor: Optional[str] = Query(None, description="æ¸¸æ ‡å€¼ï¼ˆç”¨äºæ¸¸æ ‡åˆ†é¡µï¼‰")
    ):
        self.page = page
        self.page_size = page_size
        self.cursor = cursor


# Cursor helper functions
def encode_cursor(value: Any) -> str:
    return base64.urlsafe_b64encode(str(value).encode('utf-8')).decode('utf-8')

def decode_cursor(cursor: str) -> str:
    return base64.urlsafe_b64decode(cursor.encode('utf-8')).decode('utf-8')

# Asynchronous pagination logic adapted for psycopg2
async def paginate_query(db_conn: Any, query: str, count_query: str, params: tuple, pagination: PaginationParams) -> Tuple[List[Dict], PaginationInfo]:
    def _db_calls():
        with db_conn.cursor() as cursor:
            cursor.execute(count_query, params)
            total = cursor.fetchone()[0]
            
            offset = (pagination.page - 1) * pagination.page_size
            paginated_query = f"{query} LIMIT %s OFFSET %s"
            cursor.execute(paginated_query, params + (pagination.page_size, offset))
            
            items = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            return items, columns, total

    items, columns, total = await asyncio.to_thread(_db_calls)
    
    pages = math.ceil(total / pagination.page_size) if total > 0 else 0
    
    pagination_info = PaginationInfo(
        total=total,
        page=pagination.page,
        page_size=pagination.page_size,
        pages=pages,
        has_next=pagination.page < pages,
        has_prev=pagination.page > 1,
    )
    # Transform property_description to description for consistency
    result = []
    for row in items:
        item_dict = dict(zip(columns, row))
        # Rename property_description to description if it exists
        if 'property_description' in item_dict:
            item_dict['description'] = item_dict.pop('property_description')
        result.append(item_dict)
    return result, pagination_info


# é…ç½®æ—¥å¿— - (ä¿æŒæ‚¨ç°æœ‰çš„è¯¦ç»†é…ç½®)
# Ensure this basicConfig is called only once, typically at the application entry point.
# If other modules also call basicConfig, it might lead to unexpected behavior.
# For a library/module like server.db, it's better to use logging.getLogger(__name__)
# and let the main application configure the root logger.
# However, since this is main.py, calling it here is usually fine.
if not logging.getLogger().handlers: # Configure only if no handlers are set
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - line %(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )
    logging.getLogger().setLevel(logging.DEBUG)

logger = logging.getLogger(__name__) # Module-specific logger for main.py

logger.info("FastAPIåº”ç”¨å¯åŠ¨ä¸­... æ—¥å¿—é…ç½®å·²è®¾ç½®ä¸ºDEBUGçº§åˆ« (å¦‚æœä¹‹å‰æœªé…ç½®)ã€‚")

async def check_and_optimize_indexes():
    """
    æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–ç´¢å¼•
    åªåˆ›å»ºæœ€å…³é”®çš„ç´¢å¼•ï¼Œé¿å…å¯åŠ¨æ—¶é—´è¿‡é•¿
    """
    try:
        # ä½¿ç”¨asyncpgç›´æ¥è¿æ¥æ•°æ®åº“
        import asyncpg
        database_url = os.getenv("DATABASE_URL")
        if not database_url:
            logger.warning("DATABASE_URLæœªè®¾ç½®ï¼Œè·³è¿‡ç´¢å¼•ä¼˜åŒ–")
            return
            
        conn = await asyncpg.connect(database_url)
        try:
            # æ£€æŸ¥æœ€å…³é”®çš„å¤åˆç´¢å¼•æ˜¯å¦å­˜åœ¨
            check_sql = """
                SELECT COUNT(*) FROM pg_indexes 
                WHERE tablename = 'properties' 
                AND indexname = 'idx_properties_main_filter'
            """
            result = await conn.fetchval(check_sql)
            
            if result == 0:
                logger.info("æ£€æµ‹åˆ°ç¼ºå°‘å…³é”®ç´¢å¼•ï¼Œå¼€å§‹åˆ›å»º...")
                
                # åˆ›å»ºæœ€é‡è¦çš„å¤åˆç´¢å¼•ï¼ˆè¦†ç›–90%çš„æŸ¥è¯¢åœºæ™¯ï¼‰
                # CONCURRENTLY ç¡®ä¿ä¸é”è¡¨
                critical_indexes = [
                    {
                        'name': 'idx_properties_main_filter',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_main_filter 
                            ON properties (suburb, rent_pw, bedrooms, available_date)
                            INCLUDE (address, property_type, bathrooms, parking_spaces, images)
                        """,
                        'description': 'ä¸»ç­›é€‰å¤åˆç´¢å¼•'
                    },
                    {
                        'name': 'idx_properties_available_now',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_available_now 
                            ON properties (listing_id)
                            WHERE available_date IS NULL
                        """,
                        'description': 'Available Nowå¿«é€ŸæŸ¥è¯¢'
                    },
                    {
                        'name': 'idx_properties_suburb_lower',
                        'sql': """
                            CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_properties_suburb_lower 
                            ON properties (lower(suburb))
                        """,
                        'description': 'åŒºåŸŸä¸åˆ†å¤§å°å†™æœç´¢'
                    }
                ]
                
                for index in critical_indexes:
                    try:
                        await conn.execute(index['sql'])
                        logger.info(f"âœ… åˆ›å»ºç´¢å¼•æˆåŠŸ: {index['name']} - {index['description']}")
                    except Exception as e:
                        # ç´¢å¼•å¯èƒ½å·²å­˜åœ¨æˆ–åˆ›å»ºå¤±è´¥ï¼Œä¸å½±å“å¯åŠ¨
                        logger.debug(f"ç´¢å¼• {index['name']} åˆ›å»ºè·³è¿‡: {e}")
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                await conn.execute("ANALYZE properties")
                logger.info("âœ… æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å®Œæˆï¼ŒæŸ¥è¯¢æ€§èƒ½é¢„è®¡æå‡3-5å€")
            else:
                logger.info("å…³é”®ç´¢å¼•å·²å­˜åœ¨ï¼Œè·³è¿‡ä¼˜åŒ–æ­¥éª¤")
        finally:
            await conn.close()
                
    except Exception as e:
        # ç´¢å¼•ä¼˜åŒ–å¤±è´¥ä¸åº”è¯¥é˜»æ­¢åº”ç”¨å¯åŠ¨
        logger.warning(f"ç´¢å¼•ä¼˜åŒ–è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œä½†ä¸å½±å“æœåŠ¡å¯åŠ¨: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("FastAPI application startup event triggered...")
    await init_db_pool()
    app.state.db_pool_initialized = True
    logger.info("Database pool initialization completed.")
    
    # æ£€æŸ¥å¹¶ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•ï¼ˆå¢åŠ å¯è·³è¿‡ä¸è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…å¯åŠ¨å¡æ­»ï¼‰
    # ä»…åœ¨ç”Ÿäº§ç¯å¢ƒæ‰§è¡Œï¼Œæˆ–å½“æœªæ˜¾å¼è·³è¿‡æ—¶æ‰§è¡Œ
    try:
        skip_opt = os.getenv("SKIP_INDEX_OPTIMIZATION", "").lower() in ("1", "true", "yes")
        optimize_timeout = float(os.getenv("INDEX_OPTIMIZE_TIMEOUT", "8"))
        if skip_opt or env != "production":
            logger.info(f"è·³è¿‡ç´¢å¼•ä¼˜åŒ–ï¼šSKIP_INDEX_OPTIMIZATION={skip_opt}ï¼Œenv={env}")
        else:
            logger.info(f"å¼€å§‹ç´¢å¼•ä¼˜åŒ–ï¼ˆè¶…æ—¶ {optimize_timeout}sï¼‰...")
            await asyncio.wait_for(check_and_optimize_indexes(), timeout=optimize_timeout)
    except asyncio.TimeoutError:
        logger.warning("ç´¢å¼•ä¼˜åŒ–è¶…æ—¶ï¼Œè·³è¿‡å¹¶ç»§ç»­å¯åŠ¨ã€‚")
    except Exception as e:
        logger.warning(f"ç´¢å¼•ä¼˜åŒ–æ£€æŸ¥å¤±è´¥: {e}. ç»§ç»­å¯åŠ¨...")
    
    # Initialize Redis Cache with fallback to in-memory cacheï¼ˆå¢åŠ å¯é…ç½®ä¸è¶…æ—¶ï¼‰
    try:
        redis_url = os.getenv("REDIS_URL", "").strip()
        if not redis_url:
            raise RuntimeError("REDIS_URL æœªé…ç½®ï¼Œä½¿ç”¨å†…å­˜ç¼“å­˜")
        connect_timeout = float(os.getenv("REDIS_CONNECT_TIMEOUT", "0.5"))
        socket_timeout = float(os.getenv("REDIS_SOCKET_TIMEOUT", "0.5"))
        ping_timeout = float(os.getenv("REDIS_PING_TIMEOUT", "1.0"))
        redis = aioredis.from_url(
            redis_url,
            encoding="utf8",
            decode_responses=True,
            socket_connect_timeout=connect_timeout,
            socket_timeout=socket_timeout
        )
        # Test Redis connection with timeout
        await asyncio.wait_for(redis.ping(), timeout=ping_timeout)
        app.state.redis = redis  # Store redis client in app state for cache invalidation
        FastAPICache.init(RedisBackend(redis), prefix="fastapi-cache")
        logger.info(f"FastAPI Cache initialized with Redis backend ({redis_url}).")
    except Exception as e:
        logger.warning(f"Redis ä¸å¯ç”¨æˆ–æœªé…ç½®: {e}ã€‚ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºé™çº§ã€‚")
        # ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºé™çº§æ–¹æ¡ˆ
        from fastapi_cache.backends.inmemory import InMemoryBackend
        FastAPICache.init(InMemoryBackend(), prefix="fastapi-cache")
        app.state.redis = None
        logger.info("FastAPI Cache initialized with InMemory backend (fallback).")

    yield
    # Shutdown
    logger.info("FastAPI application shutdown event triggered...")
    await close_db_pool()

# FastAPI åº”ç”¨å®ä¾‹
app = FastAPI(title="Rental MCP Server", version="1.0.0", lifespan=lifespan)
app.state.limiter = limiter

# è‡ªå®šä¹‰ç¼“å­˜é”®ï¼šä½¿ç”¨å®Œæ•´URLï¼ˆå«æŸ¥è¯¢å‚æ•°ï¼‰ä½œä¸ºç¼“å­˜é”®ï¼Œç¡®ä¿åˆ†é¡µ/ç­›é€‰ï¼ˆå°¤å…¶ page/page_sizeã€ä»·æ ¼/æ—¥æœŸï¼‰ä¸ä¼šç›¸äº’æ±¡æŸ“
# ä¸ºä»€ä¹ˆï¼šè®¡æ•°è¯·æ±‚ï¼ˆpage_size=1ï¼‰ä¸åˆ—è¡¨è¯·æ±‚ï¼ˆpage_size=20ï¼‰å‚æ•°ä¸åŒï¼Œé»˜è®¤é”®å¯èƒ½æœªåŒ…å«æŸ¥è¯¢ï¼Œå¯¼è‡´å‘½ä¸­ç›¸åŒç¼“å­˜æ¡ç›®
from fastapi import Request
def cache_key_by_url(func, namespace, request: Request, response, *args, **kwargs):
    return f"{namespace}:{str(request.url)}"

# Cache helper functions for selective invalidation
async def invalidate_property_cache(property_id: str = None):
    """Invalidate cache for a specific property or all properties"""
    redis = app.state.redis
    if not redis:
        logger.info("Cache invalidation skipped: Redis backend not configured.")
        return
    if property_id:
        # Invalidate specific property detail cache
        pattern = f"fastapi-cache:get_property_by_id:property_id={property_id}*"
    else:
        # Invalidate all property-related caches
        pattern = "fastapi-cache:get_properties*"
    
    async for key in redis.scan_iter(match=pattern):
        await redis.delete(key)
    
    logger.info(f"Cache invalidated for pattern: {pattern}")

async def invalidate_all_cache():
    """Invalidate all cache entries"""
    redis = app.state.redis
    if not redis:
        logger.info("Cache invalidation skipped: Redis backend not configured.")
        return
    async for key in redis.scan_iter(match="fastapi-cache:*"):
        await redis.delete(key)
    logger.info("All cache entries invalidated")

# CORS ä¸­é—´ä»¶é…ç½®ï¼ˆåŠ¨æ€åŒ–ï¼‰
# è¯´æ˜ï¼ˆä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼‰ï¼š
# - ç”Ÿäº§ç¯å¢ƒä»…æ”¾è¡Œæ˜ç¡®çš„å‰ç«¯åŸŸåï¼ˆå®‰å…¨ä¼˜å…ˆï¼‰
# - å¼€å‘/éç”Ÿäº§ç¯å¢ƒæ”¾å®½ï¼ˆä½¿ç”¨æ­£åˆ™ï¼‰ä»¥ä¾¿äºæœ¬åœ°è°ƒè¯•ä¸ä¸´æ—¶åŸŸåéªŒè¯
# - å…è®¸é€šè¿‡ç¯å¢ƒå˜é‡ FRONTEND_URL ä¸ ADDITIONAL_CORS é…ç½®é¢å¤–æ¥æºï¼ˆé€—å·åˆ†éš”ï¼‰
env = os.getenv("ENVIRONMENT", "development").lower()
frontend_url = os.getenv("FRONTEND_URL", "").strip()
additional_cors = os.getenv("ADDITIONAL_CORS", "").strip()

# æ”¶é›†å…è®¸çš„æ¥æºï¼ˆç”Ÿäº§ä½¿ç”¨ï¼‰
allowed_origins = {
    # å¸¸è§æœ¬åœ°æ¥æºï¼ˆç”¨äºç”Ÿäº§æ—¶ä¹Ÿå¯ä¿ç•™ä»¥ä¾¿ä¸´æ—¶è”è°ƒï¼‰
    "http://localhost",
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "http://localhost:5500",
    "http://127.0.0.1:5500",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
    "http://localhost:8888",
    "http://127.0.0.1:8888",
}

if frontend_url:
    allowed_origins.add(frontend_url)

if additional_cors:
    for origin in [x.strip() for x in additional_cors.split(",") if x.strip()]:
        allowed_origins.add(origin)

if env == "production" and allowed_origins:
    # ç”Ÿäº§ï¼šç™½åå•æ˜ç¡®åŸŸåï¼›ä¿æŒ allow_credentials=True
    app.add_middleware(
        CORSMiddleware,
        allow_origins=list(allowed_origins),
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
else:
    # å¼€å‘/éç”Ÿäº§ï¼šä½¿ç”¨æ­£åˆ™å…è®¸ä»»æ„æ¥æºï¼Œä¾¿äºæœ¬åœ°ä¸ä¸´æ—¶å…¬ç½‘åŸŸè°ƒè¯•
    # è¯´æ˜ï¼šä½¿ç”¨ allow_origin_regex å¯ä¸ allow_credentials=True å…±å­˜ï¼Œå¹¶å›æ˜¾å…·ä½“ Origin
    app.add_middleware(
        CORSMiddleware,
        allow_origin_regex=".*",
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Exception Handlers
@app.exception_handler(RateLimitExceeded)
async def rate_limit_exceeded_handler(request: Request, exc: RateLimitExceeded):
    return error_response(
        code=ErrorCodes.RATE_LIMIT_EXCEEDED,
        message=f"Rate limit exceeded: {exc.detail}",
        status_code=status.HTTP_429_TOO_MANY_REQUESTS
    )

@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    if exc.status_code == 404:
        code = ErrorCodes.RESOURCE_NOT_FOUND
    elif exc.status_code == 401:
        code = ErrorCodes.AUTHENTICATION_ERROR
    elif exc.status_code == 403:
        code = ErrorCodes.AUTHORIZATION_ERROR
    # Note: Rate limit (429) would be handled by its own library if used
    else:
        code = ErrorCodes.BAD_REQUEST
    
    return error_response(code=code, message=exc.detail, status_code=exc.status_code)

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    return error_response(
        code=ErrorCodes.VALIDATION_ERROR,
        message="Input validation failed",
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        details={"errors": exc.errors()}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"An unhandled exception occurred: {exc}", exc_info=True)
    return error_response(
        code=ErrorCodes.INTERNAL_SERVER_ERROR,
        message="An internal server error occurred.",
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
    )


# è‡ªå®šä¹‰ GraphQL ä¸Šä¸‹æ–‡è·å–å™¨
async def get_graphql_context(request: Request, db_conn: Any = Depends(get_db_conn_dependency)) -> Dict[str, Any]:
    """
    Custom context getter for GraphQL.
    Injects the database connection from the pool into the GraphQL context.
    `Depends(get_db_conn_dependency)` uses FastAPI's dependency injection.
    """
    logger.info(f"DEBUG: Type of db_conn in get_graphql_context: {type(db_conn)}") # Debug print
    # logger.debug(f"GraphQL context: db_conn type: {type(db_conn)}, id: {id(db_conn)}")
    return {
        "request": request,
        "sync_db_conn": db_conn, # The connection from the pool via get_db_conn_dependency
        # Add other context variables if needed
    }

# --- Directions Endpoint Logic ---

class TravelMode(str, Enum):
    DRIVING = "DRIVING"
    WALKING = "WALKING"
    BICYCLING = "BICYCLING"
    TRANSIT = "TRANSIT"

class DirectionsRequest(BaseModel):
    origin: str = Query(..., description="èµ·ç‚¹åæ ‡ 'lat,lng'")
    destination: str = Query(..., description="ç›®çš„åœ°åœ°å€æˆ–åæ ‡")
    mode: TravelMode = Query(TravelMode.DRIVING, description="å‡ºè¡Œæ–¹å¼")

@app.get("/api/directions", tags=["Services"])
@limiter.limit("30/minute")
async def get_directions(request: Request, params: DirectionsRequest = Depends()):
    """
    è·å–ä¸¤ä¸ªåœ°ç‚¹ä¹‹é—´çš„é€šå‹¤æ—¶é—´å’Œè·ç¦»ã€‚
    """
    api_key = os.getenv("GOOGLE_MAPS_API_KEY")
    if not api_key:
        logger.error("GOOGLE_MAPS_API_KEY not set in environment.")
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Server configuration error.",
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

    url = "https://maps.googleapis.com/maps/api/directions/json"
    request_params = {
        "origin": params.origin,
        "destination": params.destination,
        "mode": params.mode.value.lower(),
        "key": api_key
    }

    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url, params=request_params)
            response.raise_for_status()  # Will raise an exception for 4XX/5XX responses
            data = response.json()

            if data["status"] != "OK":
                logger.warning(f"Google Maps API Warn: {data['status']} - {data.get('error_message', '')}")
                return success_response(data={"duration": "N/A", "distance": "N/A", "error": data.get('status', 'No results')})

            route = data["routes"][0]
            leg = route["legs"][0]
            
            return success_response(data={
                "duration": leg["duration"]["text"],
                "distance": leg["distance"]["text"]
            })

        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error calling Google Maps API: {e.response.status_code} - {e.response.text}")
            return error_response(
                code="EXTERNAL_API_ERROR",
                message="Failed to fetch directions from external service.",
                status_code=status.HTTP_502_BAD_GATEWAY
            )
        except Exception as e:
            logger.error(f"An unexpected error occurred while fetching directions: {e}", exc_info=True)
            return error_response(
                code=ErrorCodes.INTERNAL_SERVER_ERROR,
                message="An internal error occurred.",
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


# åˆ›å»º GraphQL è·¯ç”±å™¨ï¼Œå¹¶ä½¿ç”¨è‡ªå®šä¹‰ä¸Šä¸‹æ–‡
graphql_app_router = GraphQLRouter(
    gql_schema, # Use the imported schema
    context_getter=get_graphql_context, # Pass our custom context getter
    graphql_ide="graphiql" # Enable GraphiQL interface
)
# Include routers
app.include_router(auth_router, tags=["Authentication"])
app.include_router(graphql_app_router, prefix="/graphql", tags=["GraphQL"])


@app.get("/", tags=["Root"])
async def root():
    """Root endpoint providing basic server status."""
    return {"message": "Rental MCP Server is running. Access GraphQL at /graphql"}

@app.get("/api/health", tags=["Debug"])
async def health_check():
    """A simple health check endpoint."""
    logger.info("Health check endpoint was called.")
    return {"status": "ok"}

@app.post("/api/cache/invalidate", tags=["Cache Management"])
async def invalidate_cache(
    property_id: Optional[str] = None,
    invalidate_all: bool = False
):
    """
    Invalidate cache selectively.
    - If property_id is provided, invalidate cache for that specific property
    - If invalidate_all is True, invalidate all cache entries
    - Otherwise, invalidate all property-related caches
    """
    try:
        if invalidate_all:
            await invalidate_all_cache()
            return {"status": "success", "message": "All cache entries invalidated"}
        else:
            await invalidate_property_cache(property_id)
            if property_id:
                return {"status": "success", "message": f"Cache invalidated for property {property_id}"}
            else:
                return {"status": "success", "message": "All property caches invalidated"}
    except Exception as e:
        logger.error(f"Failed to invalidate cache: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/cache/stats", tags=["Cache Management"])
async def get_cache_stats():
    """Get cache statistics"""
    try:
        redis = app.state.redis
        if not redis:
            return {
                "backend": "memory",
                "total_keys": 0,
                "property_list_cached": 0,
                "property_details_cached": 0,
                "memory_used": "N/A",
                "connected_clients": 0
            }
        info = await redis.info()
        keys_count = await redis.dbsize()
        
        # Count cache entries by pattern
        property_list_count = 0
        property_detail_count = 0
        
        async for key in redis.scan_iter(match="fastapi-cache:get_properties*"):
            property_list_count += 1
        
        async for key in redis.scan_iter(match="fastapi-cache:get_property_by_id*"):
            property_detail_count += 1
        
        return {
            "total_keys": keys_count,
            "property_list_cached": property_list_count,
            "property_details_cached": property_detail_count,
            "memory_used": info.get("used_memory_human", "N/A"),
            "connected_clients": info.get("connected_clients", 0)
        }
    except Exception as e:
        logger.error(f"Failed to get cache stats: {e}")
        return {"status": "error", "message": str(e)}

# Optional: Test endpoint for DB connection
@app.get("/test_db_connection", tags=["Debug"])
async def test_db(db: Any = Depends(get_db_conn_dependency)): # Kept async as it was
    """
    Temporarily modified to return the type of the injected 'db' object
    and check for 'cursor' attribute for debugging purposes.
    """
    # logger.info(f"DEBUG: Type of db in test_db: {type(db)}") # This log will be superseded by the response
    return {
        "status": "ok",
        "db_type": str(type(db)),
        "has_cursor": hasattr(db, "cursor")
    }

@app.get("/api/auth/test", tags=["Authentication"])
async def test_auth_system(db: Any = Depends(get_db_conn_dependency)):
    """Test endpoint to verify authentication system is working"""
    try:
        from crud.auth_crud import AuthCRUD
        
        # Test database tables exist
        with db.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM information_schema.tables WHERE table_name IN ('users', 'user_addresses')")
            table_count = cursor.fetchone()[0]
        
        # Initialize tables if they don't exist
        if table_count < 2:
            AuthCRUD.init_auth_tables(db)
            
        return {
            "status": "ok", 
            "message": "Authentication system is ready",
            "tables_initialized": True,
            "endpoints_available": [
                "/api/auth/register",
                "/api/auth/login", 
                "/api/auth/verify-email",
                "/api/auth/refresh",
                "/api/auth/me",
                "/api/auth/addresses"
            ]
        }
    except Exception as e:
        logger.error(f"Auth test error: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/email/test", tags=["Email"])
async def test_email_service():
    """Test email service configuration"""
    try:
        from services.email_service import test_email_service
        result = await test_email_service()
        return result
    except Exception as e:
        logger.error(f"Email test error: {e}")
        return {"status": "error", "message": str(e)}

@app.post("/api/email/test-send", tags=["Email"])
async def test_send_email(
    email: str = "test@example.com",
    name: str = "Test User"
):
    """Test sending a verification email (development only)"""
    try:
        from services.email_service import send_verification_email
        from config.email_config import get_email_config
        
        config = get_email_config()
        if not config.development_mode:
            return {"status": "error", "message": "Test email sending only available in development mode"}
        
        # Generate a test token
        import secrets
        test_token = secrets.token_urlsafe(32)
        
        success = await send_verification_email(email, name, test_token)
        
        return {
            "status": "success" if success else "error",
            "message": "Test email sent successfully" if success else "Failed to send test email",
            "email": email,
            "development_mode": config.development_mode,
            "test_token": test_token[:8] + "..." if success else None
        }
    except Exception as e:
        logger.error(f"Test send email error: {e}")
        return {"status": "error", "message": str(e)}

# ============== AIèŠå¤©ç³»ç»Ÿ ==============

# Pydanticæ¨¡å‹å®šä¹‰
class ChatMessage(BaseModel):
    role: str  # 'user', 'assistant', 'agent'
    content: str
    timestamp: Optional[str] = None
    agent_type: Optional[str] = None  # 'general', 'property', 'legal', 'contract', 'service'

class ChatRequest(BaseModel):
    message: str
    conversation_id: str
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    message: str
    agent_type: str
    cards: Optional[List[Dict[str, Any]]] = None
    suggestions: Optional[List[str]] = None

class PropertyCard(BaseModel):
    listing_id: int
    image: str
    price: int
    address: str
    commute: str
    bedrooms: str
    bathrooms: int
    features: List[str]

class ServiceCard(BaseModel):
    type: str
    title: str
    description: str
    price: str
    features: Optional[List[str]] = None
    action: str

# AIèŠå¤©æœåŠ¡ç±»
class ChatService:
    def __init__(self):
        self.conversations = {}  # å­˜å‚¨ä¼šè¯ä¸Šä¸‹æ–‡
        
    def route_to_agent(self, message: str) -> str:
        """æ™ºèƒ½è·¯ç”±åˆ°åˆé€‚çš„Agent"""
        msg = message.lower()
        
        # æˆ¿æºæœç´¢ç›¸å…³
        if any(keyword in msg for keyword in ['æˆ¿æº', 'æˆ¿å­', 'ç§Ÿæˆ¿', 'uts', 'unsw', 'usyd', 'é€šå‹¤', 'è·ç¦»']):
            return 'property'
        
        # æ³•å¾‹å’¨è¯¢ç›¸å…³
        if any(keyword in msg for keyword in ['æ³•å¾‹', 'æƒç›Š', 'æŠ¼é‡‘', 'æˆ¿ä¸œ', 'ç§Ÿå®¢', 'è¿çº¦']):
            return 'legal'
        
        # åˆåŒå®¡æ ¸ç›¸å…³
        if any(keyword in msg for keyword in ['åˆåŒ', 'æ¡æ¬¾', 'ç­¾çº¦', 'åè®®', 'å®¡æ ¸']):
            return 'contract'
        
        # æœåŠ¡ç›¸å…³
        if any(keyword in msg for keyword in ['ä»£çœ‹æˆ¿', 'æ¬å®¶', 'å’¨è¯¢', 'é¢„çº¦', 'æœåŠ¡']):
            return 'service'
        
        return 'general'
    
    async def process_message(self, request: ChatRequest, db_conn: Any) -> ChatResponse:
        """å¤„ç†èŠå¤©æ¶ˆæ¯"""
        message = request.message
        conversation_id = request.conversation_id
        
        # è·¯ç”±åˆ°åˆé€‚çš„Agent
        agent_type = self.route_to_agent(message)
        
        # æ ¹æ®Agentç±»å‹å¤„ç†æ¶ˆæ¯
        if agent_type == 'property':
            return await self.handle_property_query(message, db_conn)
        elif agent_type == 'legal':
            return await self.handle_legal_query(message)
        elif agent_type == 'contract':
            return await self.handle_contract_query(message)
        elif agent_type == 'service':
            return await self.handle_service_query(message)
        else:
            return await self.handle_general_query(message)
    
    async def handle_property_query(self, message: str, db_conn: Any) -> ChatResponse:
        """å¤„ç†æˆ¿æºæŸ¥è¯¢"""
        msg = message.lower()
        
        # æ£€æŸ¥æ˜¯å¦è¯¢é—®å¤§å­¦ç›¸å…³
        universities = ['uts', 'unsw', 'usyd', 'macquarie', 'æ‚‰å°¼ç§‘æŠ€å¤§å­¦', 'æ–°å—å¨å°”å£«å¤§å­¦', 'æ‚‰å°¼å¤§å­¦']
        mentioned_uni = None
        for uni in universities:
            if uni in msg:
                mentioned_uni = uni
                break
        
        if mentioned_uni:
            uni_name = self.get_university_name(mentioned_uni)
            response_text = f"å¥½çš„ï¼æˆ‘æ¥ä¸ºæ‚¨æ¨è{uni_name}é™„è¿‘çš„æˆ¿æºã€‚"
            
            # æ¨¡æ‹Ÿæˆ¿æºæ•°æ®ï¼ˆå®é™…åº”è¯¥ä»æ•°æ®åº“æŸ¥è¯¢ï¼‰
            property_cards = [
                {
                    "id": 1,
                    "image": "https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?w=300&h=200&fit=crop",
                    "price": 776,
                    "address": "Central Park Student Village",
                    "commute": "UTSæ­¥è¡Œ8åˆ†é’Ÿ",
                    "bedrooms": "Studio",
                    "bathrooms": 1,
                    "features": ["ç©ºè°ƒ", "æ´—è¡£æœº", "é«˜é€Ÿç½‘ç»œ"]
                },
                {
                    "id": 2,
                    "image": "https://images.unsplash.com/photo-1564013799919-ab600027ffc6?w=300&h=200&fit=crop",
                    "price": 706,
                    "address": "Redfern Student Accommodation",
                    "commute": "UTSè½»è½¨10åˆ†é’Ÿ",
                    "bedrooms": "Studio",
                    "bathrooms": 1,
                    "features": ["å¥èº«æˆ¿", "åœè½¦ä½", "å®‰ä¿"]
                }
            ]
            
            return ChatResponse(
                message=response_text,
                agent_type="property",
                cards=property_cards,
                suggestions=["æŸ¥çœ‹æ›´å¤šæˆ¿æº", "é¢„çº¦ä»£çœ‹æˆ¿", "äº†è§£é€šå‹¤è¯¦æƒ…"]
            )
        else:
            return ChatResponse(
                message="æˆ‘æ¥å¸®æ‚¨æ‰¾æˆ¿æºï¼è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼š\n\nâ€¢ æ‚¨åœ¨å“ªæ‰€å¤§å­¦ä¸Šå­¦ï¼Ÿ\nâ€¢ é¢„ç®—èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿ\nâ€¢ åå¥½çš„åŒºåŸŸæˆ–äº¤é€šæ–¹å¼ï¼Ÿ",
                agent_type="property",
                suggestions=["UTSé™„è¿‘æˆ¿æº", "UNSWé™„è¿‘æˆ¿æº", "USYDé™„è¿‘æˆ¿æº", "é¢„ç®—$500-800"]
            )
    
    async def handle_legal_query(self, message: str) -> ChatResponse:
        """å¤„ç†æ³•å¾‹å’¨è¯¢"""
        msg = message.lower()
        
        if 'æŠ¼é‡‘' in msg:
            response = """å…³äºæŠ¼é‡‘çš„æ³•å¾‹è§„å®šï¼š

**æŠ¼é‡‘æ ‡å‡†**ï¼š
â€¢ ä¸€èˆ¬ä¸è¶…è¿‡4å‘¨ç§Ÿé‡‘
â€¢ å¿…é¡»å­˜å…¥æ”¿åºœç›‘ç®¡è´¦æˆ·
â€¢ ä¸èƒ½ç”¨ä½œæœ€åä¸€æœŸç§Ÿé‡‘

**é€€è¿˜æ¡ä»¶**ï¼š
â€¢ æˆ¿å±‹æ— æŸåï¼šå…¨é¢é€€è¿˜
â€¢ æœ‰æŸåï¼šæ‰£é™¤ç»´ä¿®è´¹åé€€è¿˜
â€¢ 14å¤©å†…å¿…é¡»å¤„ç†

**æˆ‘ä»¬çš„å»ºè®®**ï¼š
ç­¾çº¦æ—¶æ‹ç…§è®°å½•æˆ¿å±‹çŠ¶æ€ï¼Œæ¬å‡ºæ—¶ä¹Ÿè¦æ‹ç…§å¯¹æ¯”ã€‚"""
        elif 'æˆ¿ä¸œ' in msg or 'æƒç›Š' in msg:
            response = """æ¾³æ´²ç§Ÿå®¢æƒç›Šä¿æŠ¤ï¼š

**æˆ¿ä¸œä¸èƒ½**ï¼š
â€¢ éšæ„è¿›å…¥æ‚¨çš„æˆ¿é—´
â€¢ æ— ç†ç”±é©±èµ¶ç§Ÿå®¢
â€¢ æ­§è§†æ€§å¯¹å¾…

**æ‚¨çš„æƒåˆ©**ï¼š
â€¢ å®‰é™äº«ç”¨æƒ
â€¢ ç»´ä¿®è¦æ±‚æƒ
â€¢ éšç§ä¿æŠ¤æƒ

**éœ€è¦å¸®åŠ©æ—¶**ï¼š
â€¢ è”ç³»å½“åœ°ç§Ÿå®¢åä¼š
â€¢ ç”³è¯·ä»²è£æœåŠ¡
â€¢ å¯»æ±‚æ³•å¾‹æ´åŠ©"""
        else:
            response = """æˆ‘æ˜¯æ‚¨çš„ç§Ÿèµæ³•å¾‹é¡¾é—®ï¼æˆ‘å¯ä»¥å¸®æ‚¨è§£ç­”ï¼š

â€¢ ç§Ÿæˆ¿åˆåŒæ¡æ¬¾è§£é‡Š
â€¢ æŠ¼é‡‘å’Œç§Ÿé‡‘ç›¸å…³æ³•è§„
â€¢ ç§Ÿå®¢æƒç›Šä¿æŠ¤
â€¢ æˆ¿ä¸œè´£ä»»ä¹‰åŠ¡
â€¢ è¿çº¦å’Œçº çº·å¤„ç†

è¯·å…·ä½“å‘Šè¯‰æˆ‘æ‚¨é‡åˆ°çš„é—®é¢˜ï¼Ÿ"""
        
        service_card = {
            "type": "legal",
            "title": "âš–ï¸ ä¸“ä¸šæ³•å¾‹å’¨è¯¢",
            "description": "å¤æ‚æ¡ˆä¾‹äººå·¥æ³•å¾‹é¡¾é—®",
            "price": "$99",
            "features": ["30åˆ†é’Ÿä¸“ä¸šå’¨è¯¢", "ä¹¦é¢æ„è§ä¹¦", "ä¸­æ–‡å…¨ç¨‹æœåŠ¡"],
            "action": "é¢„çº¦å’¨è¯¢"
        }
        
        return ChatResponse(
            message=response,
            agent_type="legal",
            cards=[service_card],
            suggestions=["æŠ¼é‡‘é—®é¢˜", "æˆ¿ä¸œçº çº·", "åˆåŒæ¡æ¬¾", "é¢„çº¦æ³•å¾‹å’¨è¯¢"]
        )
    
    async def handle_contract_query(self, message: str) -> ChatResponse:
        """å¤„ç†åˆåŒå®¡æ ¸"""
        response = """æˆ‘å¯ä»¥å¸®æ‚¨å®¡æ ¸ç§Ÿæˆ¿åˆåŒï¼

**AIå¿«é€Ÿå®¡æ ¸**ï¼š
â€¢ 30ç§’è¯†åˆ«å…³é”®æ¡æ¬¾
â€¢ æ ‡æ³¨æ½œåœ¨é£é™©ç‚¹
â€¢ æä¾›ä¿®æ”¹å»ºè®®
â€¢ ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š

**å¸¸è§é£é™©æ¡æ¬¾**ï¼š
â€¢ è¿‡é«˜çš„è¿çº¦é‡‘
â€¢ ä¸åˆç†çš„ç»´ä¿®è´£ä»»
â€¢ æ¨¡ç³Šçš„æŠ¼é‡‘æ¡æ¬¾
â€¢ é™åˆ¶æ€§ä½¿ç”¨è§„å®š

ä¸Šä¼ æ‚¨çš„åˆåŒï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†åˆ†æï¼"""
        
        service_card = {
            "type": "contract",
            "title": "ğŸ“‹ AIåˆåŒå®¡æ ¸",
            "description": "æ™ºèƒ½è¯†åˆ«é£é™©æ¡æ¬¾",
            "price": "$25",
            "features": ["30ç§’å¿«é€Ÿåˆ†æ", "é£é™©ç‚¹æ ‡æ³¨", "ä¿®æ”¹å»ºè®®", "ä¸“ä¸šæŠ¥å‘Š"],
            "action": "ä¸Šä¼ åˆåŒ"
        }
        
        return ChatResponse(
            message=response,
            agent_type="contract",
            cards=[service_card],
            suggestions=["ä¸Šä¼ åˆåŒ", "å¸¸è§æ¡æ¬¾è¯´æ˜", "é£é™©æ¡ˆä¾‹", "æ³•å¾‹å»ºè®®"]
        )
    
    async def handle_service_query(self, message: str) -> ChatResponse:
        """å¤„ç†æœåŠ¡æŸ¥è¯¢"""
        msg = message.lower()
        
        if 'ä»£çœ‹æˆ¿' in msg:
            response = "æˆ‘æ¥ä¸ºæ‚¨ä»‹ç»ä»£çœ‹æˆ¿æœåŠ¡ï¼è¿™æ˜¯æˆ‘ä»¬æœ€å—æ¬¢è¿çš„æœåŠ¡ã€‚"
            
            service_card = {
                "type": "inspection",
                "title": "ğŸ  ä¸“ä¸šä»£çœ‹æˆ¿æœåŠ¡",
                "description": "ä¸“ä¸šé¡¾é—®å®åœ°çœ‹æˆ¿æ‹æ‘„",
                "price": "$35",
                "features": ["ä¸“ä¸šæ‹æ‘„å½•åƒ", "è¯¦ç»†è¯„ä¼°æŠ¥å‘Š", "2å°æ—¶å†…å®Œæˆ", "å¾®ä¿¡å®æ—¶æ²Ÿé€š"],
                "action": "ç«‹å³é¢„çº¦"
            }
            
            return ChatResponse(
                message=response,
                agent_type="service",
                cards=[service_card],
                suggestions=["é¢„çº¦ä»£çœ‹æˆ¿", "æŸ¥çœ‹æœåŠ¡è¯¦æƒ…", "ä»·æ ¼è¯´æ˜", "æœåŠ¡æµç¨‹"]
            )
        else:
            response = "æˆ‘ä»¬æä¾›å…¨æ–¹ä½çš„ç§Ÿæˆ¿æœåŠ¡ï¼"
            
            service_cards = [
                {
                    "type": "inspection",
                    "title": "ğŸ  ä»£çœ‹æˆ¿æœåŠ¡",
                    "description": "ä¸“ä¸šå®åœ°çœ‹æˆ¿å½•åƒ",
                    "price": "$35",
                    "action": "ç«‹å³é¢„çº¦"
                },
                {
                    "type": "moving",
                    "title": "ğŸšš å­¦ç”Ÿæ¬å®¶",
                    "description": "å°ä»¶ç‰©å“æ¬è¿",
                    "price": "$89èµ·",
                    "action": "è·å–æŠ¥ä»·"
                },
                {
                    "type": "consultation",
                    "title": "ğŸ’¼ ç­¾çº¦é™ªåŒ",
                    "description": "ä¸­æ–‡å…¨ç¨‹é™ªåŒ",
                    "price": "$59",
                    "action": "é¢„çº¦æœåŠ¡"
                }
            ]
            
            return ChatResponse(
                message=response,
                agent_type="service",
                cards=service_cards,
                suggestions=["ä»£çœ‹æˆ¿æœåŠ¡", "æ¬å®¶æœåŠ¡", "ç­¾çº¦é™ªåŒ", "å…¨å¥—æœåŠ¡åŒ…"]
            )
    
    async def handle_general_query(self, message: str) -> ChatResponse:
        """å¤„ç†é€šç”¨æŸ¥è¯¢"""
        msg = message.lower()
        
        if 'ä½ å¥½' in msg or 'hello' in msg:
            response = "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ ğŸ˜Š æˆ‘æ˜¯æ‚¨çš„ä¸“å±ç§Ÿæˆ¿åŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨æ‰¾æˆ¿æºã€å®‰æ’çœ‹æˆ¿ã€è§£ç­”æ³•å¾‹é—®é¢˜ã€‚æ‚¨æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ"
        elif 'ä»·æ ¼' in msg or 'å¤šå°‘é’±' in msg:
            response = """æˆ‘ä»¬çš„æœåŠ¡ä»·æ ¼é€æ˜å…¬å¼€ï¼š

ğŸ  **ä»£çœ‹æˆ¿æœåŠ¡**: $35/æ¬¡
ğŸ“‹ **åˆåŒå®¡æ ¸**: $25/ä»½  
âš–ï¸ **æ³•å¾‹å’¨è¯¢**: $99/æ¬¡
ğŸšš **æ¬å®¶æœåŠ¡**: $89èµ·
ğŸ’¼ **ç­¾çº¦é™ªåŒ**: $59/æ¬¡

æ‰€æœ‰æœåŠ¡éƒ½æ˜¯ä¸€æ¬¡æ€§æ”¶è´¹ï¼Œæ— éšè—è´¹ç”¨ï¼éœ€è¦äº†è§£å…·ä½“å“ªé¡¹æœåŠ¡ï¼Ÿ"""
        elif 'å¤§å­¦' in msg or 'å­¦æ ¡' in msg:
            response = """æˆ‘ä»¬ä¸»è¦æœåŠ¡è¿™äº›å¤§å­¦çš„å­¦ç”Ÿï¼š

ğŸ« **æ‚‰å°¼ç§‘æŠ€å¤§å­¦** (UTS)
ğŸ« **æ–°å—å¨å°”å£«å¤§å­¦** (UNSW)  
ğŸ« **æ‚‰å°¼å¤§å­¦** (USYD)
ğŸ« **éº¦è€ƒç‘å¤§å­¦** (Macquarie)

è¯·å‘Šè¯‰æˆ‘æ‚¨åœ¨å“ªæ‰€å¤§å­¦ï¼Œæˆ‘æ¥ä¸ºæ‚¨æ¨èé™„è¿‘çš„ä¼˜è´¨æˆ¿æºï¼"""
        else:
            response = """æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ã€‚ä½œä¸ºä¸“ä¸šçš„ç§Ÿæˆ¿åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ï¼š

ğŸ” **æ™ºèƒ½æ‰¾æˆ¿**: æ ¹æ®å¤§å­¦æ¨èæˆ¿æº
ğŸ  **ä»£çœ‹æˆ¿æœåŠ¡**: $35ä¸“ä¸šå®åœ°çœ‹æˆ¿  
ğŸ“‹ **åˆåŒå®¡æ ¸**: AIå¿«é€Ÿè¯†åˆ«é£é™©æ¡æ¬¾
âš–ï¸ **æ³•å¾‹å’¨è¯¢**: ä¸“ä¸šç§Ÿæˆ¿æ³•å¾‹å»ºè®®
ğŸšš **é…å¥—æœåŠ¡**: æ¬å®¶ã€ç­¾çº¦é™ªåŒç­‰

æ‚¨æœ€æƒ³äº†è§£å“ªæ–¹é¢ï¼Ÿ"""
        
        return ChatResponse(
            message=response,
            agent_type="general",
            suggestions=["æ‰¾æˆ¿æº", "ä»£çœ‹æˆ¿æœåŠ¡", "æ³•å¾‹å’¨è¯¢", "ä»·æ ¼è¯´æ˜"]
        )
    
    def get_university_name(self, uni_code: str) -> str:
        """è·å–å¤§å­¦ä¸­æ–‡åç§°"""
        names = {
            'uts': 'æ‚‰å°¼ç§‘æŠ€å¤§å­¦',
            'unsw': 'æ–°å—å¨å°”å£«å¤§å­¦', 
            'usyd': 'æ‚‰å°¼å¤§å­¦',
            'macquarie': 'éº¦è€ƒç‘å¤§å­¦',
            'æ‚‰å°¼ç§‘æŠ€å¤§å­¦': 'æ‚‰å°¼ç§‘æŠ€å¤§å­¦',
            'æ–°å—å¨å°”å£«å¤§å­¦': 'æ–°å—å¨å°”å£«å¤§å­¦',
            'æ‚‰å°¼å¤§å­¦': 'æ‚‰å°¼å¤§å­¦'
        }
        return names.get(uni_code.lower(), uni_code)

# åˆ›å»ºèŠå¤©æœåŠ¡å®ä¾‹
chat_service = ChatService()

# AIèŠå¤©APIç«¯ç‚¹
@app.post("/api/chat", response_model=ChatResponse, tags=["AI Chat"])
async def chat_endpoint(request: ChatRequest, db_conn: Any = Depends(get_db_conn_dependency)):
    """AIèŠå¤©APIç«¯ç‚¹"""
    try:
        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message}")
        response = await chat_service.process_message(request, db_conn)
        logger.info(f"èŠå¤©å“åº”: {response.message[:100]}...")
        return response
    except Exception as e:
        logger.error(f"èŠå¤©å¤„ç†é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"èŠå¤©å¤„ç†å¤±è´¥: {str(e)}")

# Note: Ensure that `server.api.graphql_schema.py` uses `info.context.get('sync_db_conn')`
# to retrieve the database connection in its resolvers.
# The `get_db_session` context manager will handle returning the connection to the pool.

# --- Celery Task Endpoints ---
from celery_config import celery_app
from tasks import debug_task, example_db_task
from celery.result import AsyncResult

@app.post("/api/tasks/debug", status_code=status.HTTP_202_ACCEPTED, tags=["Tasks"])
async def start_debug_task(api_key: str = Security(get_api_key)):
    """Endpoint to trigger the simple debug task."""
    try:
        logger.info("Attempting to queue debug_task...")
        task = debug_task.delay()
        logger.info(f"Task {task.id} queued successfully.")
        return success_response(data={"task_id": task.id, "message": "Debug task started"})
    except Exception as e:
        logger.error(f"Failed to queue debug_task: {e}", exc_info=True)
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Failed to queue task.",
            status_code=500
        )

@app.post("/api/tasks/db", status_code=status.HTTP_202_ACCEPTED, tags=["Tasks"])
async def start_db_task(api_key: str = Security(get_api_key)):
    """Endpoint to trigger the example database task."""
    try:
        logger.info("Attempting to queue example_db_task...")
        # Pass some example data to the task
        task = example_db_task.delay("Hello from FastAPI endpoint!")
        logger.info(f"Task {task.id} queued successfully.")
        return success_response(data={"task_id": task.id, "message": "Database task started"})
    except Exception as e:
        logger.error(f"Failed to queue db_task: {e}", exc_info=True)
        return error_response(
            code=ErrorCodes.INTERNAL_SERVER_ERROR,
            message="Failed to queue task.",
            status_code=500
        )

@app.get("/api/tasks/{task_id}", tags=["Tasks"], response_model=APIResponse)
async def get_task_status(task_id: str, api_key: str = Security(get_api_key)):
    """Endpoint to check the status of a Celery task."""
    task_result = AsyncResult(task_id, app=celery_app)
    
    response_data = {
        "task_id": task_id,
        "status": task_result.status,
        "result": task_result.result if task_result.ready() else None,
    }

    if task_result.failed():
        return error_response(
            code="TASK_FAILED",
            message="The task failed to execute.",
            status_code=500,
            details=response_data
        )
        
    return success_response(data=response_data)
# --- End Celery Task Endpoints ---

from crud.properties_crud import get_property_by_id_from_db

@app.get("/api/properties/{property_id}", tags=["Properties"], response_model=APIResponse[Dict])
@cache(expire=1800)  # Cache for 30 minutes
async def get_property_by_id(property_id: str, db: Any = Depends(get_db_conn_dependency)):
    """
    Get a single property by its ID.
    """
    logger.info(f"====== HIT get_property_by_id with ID: {property_id} ======")
    # In a real app, you would have a CRUD function to get a single property
    # For now, we'll fetch all and filter, which is inefficient.
    # This should be replaced with a direct DB call.
    # NOTE: This is a placeholder implementation.
    
    # Correct implementation:
    prop = await asyncio.to_thread(get_property_by_id_from_db, property_id)
    if not prop:
        return error_response(
            code=ErrorCodes.RESOURCE_NOT_FOUND,
            message=f"Property with ID {property_id} not found.",
            status_code=status.HTTP_404_NOT_FOUND
        )
    
    # Manually convert the Strawberry object to a dictionary
    prop_dict = {
        "listing_id": prop.listing_id,
        "address": prop.address,
        "suburb": prop.suburb,
        "rent_pw": prop.rent_pw,
        "bedrooms": prop.bedrooms,
        "bathrooms": prop.bathrooms,
        "property_type": prop.property_type,
        "property_url": prop.property_url,
        "postcode": prop.postcode,
        "bond": prop.bond,
        "parking_spaces": prop.parking_spaces,
        "available_date": prop.available_date,
        "images": prop.images,
        "property_features": prop.property_features,
        "latitude": prop.latitude,
        "longitude": prop.longitude,
        "geom_wkt": prop.geom_wkt,
        "is_furnished": prop.is_furnished,
        "description": prop.description,  # Add description field
        "property_headline": prop.property_headline,  # æ·»åŠ æˆ¿æºæ ‡é¢˜å­—æ®µ
        "inspection_times": prop.inspection_times  # è¡¥å……çœ‹æˆ¿æ—¶é—´å­—æ®µï¼Œä¿®å¤åˆ·æ–°åæ¶ˆå¤±
    }
    
    return success_response(data=prop_dict)


@app.get("/api/properties", tags=["Properties"], response_model=APIResponse[List[Dict]])
@cache(expire=900, key_builder=cache_key_by_url)  # Cache for 15 minutesï¼ˆåŒ…å«URLæŸ¥è¯¢å‚æ•°åˆ°ç¼“å­˜é”®ï¼‰
async def get_properties(
    pagination: PaginationParams = Depends(), 
    db: Any = Depends(get_db_conn_dependency),
    # Filter parameters
    suburb: Optional[str] = None,
    property_type: Optional[str] = None,
    bedrooms: Optional[str] = None,  # Can be comma-separated like "1,2,3"
    bathrooms: Optional[str] = None,  # Can be comma-separated like "1,2"
    parking: Optional[str] = None,  # Can be comma-separated like "0,1,2"
    minPrice: Optional[int] = None,
    maxPrice: Optional[int] = None,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None,
    isFurnished: Optional[bool] = None,
    # å…¼å®¹å‚æ•°ï¼ˆV2/éƒ¨åˆ†å…¥å£ï¼‰ï¼šå¦‚ä¼ å…¥ furnished=trueï¼Œåˆ™ç­‰ä»·äº isFurnished=true
    furnished: Optional[bool] = None,
    # ç‚¹åè¿‡æ»¤ï¼ˆä¾¿äºæ ¡éªŒï¼‰
    listing_id: Optional[str] = None,
    # æ’åºå‚æ•°ï¼ˆç™½åå•ï¼‰ï¼šprice_asc/available_date_asc/suburb_az/inspection_earliest
    sort: Optional[str] = None,
):
    """
    Get a paginated list of properties with optional filters.
    Supports both page-based and cursor-based pagination.
    """
    # Build the base query with filters - åªé€‰æ‹©åˆ—è¡¨é¡µéœ€è¦çš„å­—æ®µï¼Œå‡å°‘æ•°æ®ä¼ è¾“
    # æ’é™¤å¤§å­—æ®µå¦‚ description å’Œ property_featuresï¼Œæå‡æ€§èƒ½
    base_query = """SELECT 
        listing_id, property_url, address, suburb, state, postcode, 
        property_type, rent_pw, bond, bedrooms, bathrooms, parking_spaces,
        available_date, inspection_times, agency_name, agent_name,
        property_headline, latitude, longitude, images,
        is_active, status, created_at, last_updated,
        has_air_conditioning, is_furnished, has_balcony, has_dishwasher,
        has_laundry, has_parking, has_pool, has_gym
    FROM properties"""
    count_query = "SELECT COUNT(*) FROM properties"
    
    # Build WHERE clause conditions
    conditions = []
    params = []
    
    # å§‹ç»ˆåªè¿”å›æ´»è·ƒçš„æˆ¿æºï¼ˆå…³é”®ä¿®å¤ï¼šè¿‡æ»¤å·²ä¸‹æ¶æˆ¿æºï¼‰
    conditions.append("is_active = TRUE")
    
    # æŒ‡å®š listing_id æ—¶åšç‚¹åè¿‡æ»¤ï¼ˆä¾¿äºæ ¡éªŒ/å¤ç°å•æ¡ï¼‰
    if listing_id:
        try:
            lid = int(listing_id)
            conditions.append("listing_id = %s")
            params.append(lid)
        except (ValueError, TypeError):
            # å¿½ç•¥éæ³• idï¼Œä¸å½±å“å…¶ä»–æ¡ä»¶
            pass

    # Add suburb filter - support multiple suburbs (comma-separated)
    if suburb:
        # Split by comma and trim whitespace
        suburbs = [s.strip() for s in suburb.split(',')]
        if len(suburbs) == 1:
            # Single suburb - use ILIKE for partial matching
            conditions.append("suburb ILIKE %s")
            params.append(f"%{suburbs[0]}%")
        else:
            # Multiple suburbs - use ILIKE with OR for case-insensitive matching
            suburb_conditions = []
            for sub in suburbs:
                suburb_conditions.append("suburb ILIKE %s")
                params.append(f"%{sub}%")
            conditions.append(f"({' OR '.join(suburb_conditions)})")
    
    # Add property type filter
    if property_type:
        conditions.append("property_type ILIKE %s")
        params.append(f"%{property_type}%")
    
    # Add bedrooms filter (handle comma-separated values)
    if bedrooms:
        bedroom_values = bedrooms.split(',')
        bedroom_conditions = []
        bedroom_params: List[int] = []
        for value in bedroom_values:
            value = value.strip()
            if value == '4+':
                bedroom_conditions.append("bedrooms >= %s")
                bedroom_params.append(4)
            elif value.isdigit():
                bedroom_conditions.append("bedrooms = %s")
                bedroom_params.append(int(value))
        if bedroom_conditions:
            conditions.append(f"({' OR '.join(bedroom_conditions)})")
            params.extend(bedroom_params)
    
    # Add bathrooms filter (handle comma-separated values)
    if bathrooms:
        bathroom_values = bathrooms.split(',')
        bathroom_conditions = []
        bathroom_params: List[int] = []
        for value in bathroom_values:
            value = value.strip()
            if value == '3+':
                bathroom_conditions.append("bathrooms >= %s")
                bathroom_params.append(3)
            elif value.isdigit():
                bathroom_conditions.append("bathrooms = %s")
                bathroom_params.append(int(value))
        if bathroom_conditions:
            conditions.append(f"({' OR '.join(bathroom_conditions)})")
            params.extend(bathroom_params)
    
    # Add parking filter (handle comma-separated values)
    if parking:
        parking_values = parking.split(',')
        parking_conditions = []
        parking_params: List[int] = []
        for value in parking_values:
            value = value.strip()
            if value == '2+':
                parking_conditions.append("parking_spaces >= %s")
                parking_params.append(2)
            elif value.isdigit():
                parking_conditions.append("parking_spaces = %s")
                parking_params.append(int(value))
        if parking_conditions:
            conditions.append(f"({' OR '.join(parking_conditions)})")
            params.extend(parking_params)
    
    # Add price range filters
    if minPrice is not None:
        conditions.append("rent_pw >= %s")
        params.append(minPrice)
    
    if maxPrice is not None:
        conditions.append("rent_pw <= %s")
        params.append(maxPrice)
    
    # Add date filters
    # å¤„ç†ç©ºå‡ºæ—¥æœŸç­›é€‰é€»è¾‘ï¼š
    # - NULLè¡¨ç¤º"Available now"ï¼ˆç«‹å³å¯å…¥ä½ï¼‰
    # - date_fromåˆ°date_toï¼šç­›é€‰åœ¨è¿™ä¸ªæ—¶é—´æ®µå†…ç©ºå‡ºçš„æˆ¿æº
    # - å¦‚æœæ—¶é—´æ®µåŒ…å«ä»Šå¤©æˆ–è¿‡å»ï¼ŒNULLï¼ˆAvailable nowï¼‰åº”è¯¥è¢«åŒ…å«
    from datetime import datetime
    today = datetime.now().date()
    
    if date_from and date_to:
        # ç”¨æˆ·é€‰æ‹©äº†æ—¶é—´èŒƒå›´ï¼šæ‰¾åœ¨è¿™ä¸ªæ—¶é—´æ®µå†…ç©ºå‡ºçš„æˆ¿æº
        # å¦‚æœdate_from <= ä»Šå¤©ï¼ŒåŒ…å«Available nowçš„æˆ¿æº
        if datetime.strptime(date_from, '%Y-%m-%d').date() <= today:
            conditions.append(
                "(available_date IS NULL OR (available_date >= %s AND available_date <= %s))"
            )
        else:
            # æœªæ¥çš„æ—¶é—´æ®µï¼Œä¸åŒ…å«Available now
            conditions.append(
                "(available_date >= %s AND available_date <= %s)"
            )
        params.append(date_from)
        params.append(date_to)
    elif date_from:
        # åªæœ‰å¼€å§‹æ—¥æœŸï¼šæ‰¾ä»è¿™ä¸ªæ—¥æœŸä¹‹åç©ºå‡ºçš„æˆ¿æº
        if datetime.strptime(date_from, '%Y-%m-%d').date() <= today:
            conditions.append(
                "(available_date IS NULL OR available_date >= %s)"
            )
        else:
            conditions.append("available_date >= %s")
        params.append(date_from)
    elif date_to:
        # åªæœ‰ç»“æŸæ—¥æœŸï¼šæ‰¾åœ¨è¿™ä¸ªæ—¥æœŸä¹‹å‰ç©ºå‡ºçš„æˆ¿æº
        conditions.append(
            "(available_date IS NULL OR available_date <= %s)"
        )
        params.append(date_to)
    
    # å®¶å…·ç­›é€‰ï¼ˆå…¼å®¹ isFurnished ä¸ furnished ä¸¤ä¸ªé”®ï¼›ä»…å½“æ˜¾å¼ä¸º true/false æ—¶æ‰ç­›ï¼‰
    # è¯´æ˜ï¼šå°† is_furnished ç»Ÿä¸€è½¬ä¸ºæ–‡æœ¬ååšé›†åˆåŒ¹é…ï¼Œé¿å…å†å² text/ä¸‰æ€å¯¼è‡´çš„ 500ï¼›ä¸ä¼šæŠŠ 'unknown' å½“ true/false
    effectiveFurnished = isFurnished if isFurnished is not None else furnished
    if effectiveFurnished is not None:
        if effectiveFurnished:
            conditions.append("NULLIF(TRIM(LOWER(is_furnished::text)), '') IN ('t','true','yes','1')")
        else:
            conditions.append("NULLIF(TRIM(LOWER(is_furnished::text)), '') IN ('f','false','no','0')")
    
    # Build WHERE clause
    where_clause = ""
    if conditions:
        where_clause = " WHERE " + " AND ".join(conditions)
    
    # Update queries with WHERE clause
    base_query += where_clause
    count_query += where_clause

    # æ’åºæ˜ å°„ï¼ˆä¸ºä»€ä¹ˆï¼šè®©å‰ç«¯ Sort çœŸæ­£ç”Ÿæ•ˆï¼›ä»…å…è®¸ç™½åå•ï¼Œé˜²æ³¨å…¥ï¼›å¹¶é™„åŠ  listing_id ASC ä½œä¸ºç¨³å®šæ¬¡åºé”®ï¼‰
    order_clause = " ORDER BY listing_id ASC"
    if sort:
        s = str(sort).strip().lower()
        if s == "price_asc":
            order_clause = " ORDER BY rent_pw ASC NULLS LAST, listing_id ASC"
        elif s == "available_date_asc":
            order_clause = " ORDER BY available_date ASC NULLS FIRST, listing_id ASC"
        elif s == "suburb_az":
            order_clause = " ORDER BY lower(suburb) ASC NULLS LAST, listing_id ASC"
        elif s == "inspection_earliest":
            # TODOï¼šP1 ç²¾ç¡®è§£æ inspection_times çš„â€œæœ€æ—©çœ‹æˆ¿æ—¶é—´â€è¿›è¡Œæ’åº
            # å½“å‰å…ˆä¸ available_date_asc ç­‰ä»·ï¼Œæ»¡è¶³ P0 çœŸæ­£ç”Ÿæ•ˆçš„å‰ç«¯è¡¨ç°
            order_clause = " ORDER BY available_date ASC NULLS FIRST, listing_id ASC"
    
    
    # Simple cursor implementation based on listing_id
    # A more robust implementation would handle sorting
    if pagination.cursor:
        try:
            cursor_val = int(decode_cursor(pagination.cursor))
            # Add cursor condition to existing WHERE clause
            if where_clause:
                query = f"{base_query} AND listing_id > %s ORDER BY listing_id ASC"
            else:
                query = f"{base_query} WHERE listing_id > %s ORDER BY listing_id ASC"
            # Append cursor value to existing params
            cursor_params = params + [cursor_val]
        except (ValueError, TypeError):
            raise HTTPException(status_code=400, detail="Invalid cursor")

        def _db_call_cursor():
            with db.cursor() as cur:
                # Fetch one more than page_size to check for has_next
                cur.execute(f"{query} LIMIT %s", cursor_params + [pagination.page_size + 1])
                items = cur.fetchall()
                columns = [desc[0] for desc in cur.description]
                return items, columns
        
        items, columns = await asyncio.to_thread(_db_call_cursor)
        
        has_next = len(items) > pagination.page_size
        if has_next:
            items = items[:-1] # remove extra item
        
        items_as_dicts = []
        for row in items:
            item_dict = dict(zip(columns, row))
            # Rename property_description to description if it exists
            if 'property_description' in item_dict:
                item_dict['description'] = item_dict.pop('property_description')
            items_as_dicts.append(item_dict)
        next_cursor = encode_cursor(items_as_dicts[-1]['listing_id']) if items_as_dicts and has_next else None

        pagination_info = PaginationInfo(
            total=-1, # Cursor pagination doesn't usually return total
            page=1, # Page number is not relevant for cursor
            page_size=pagination.page_size,
            pages=-1,
            has_next=has_next,
            has_prev=pagination.cursor is not None,
            next_cursor=next_cursor
        )
        return success_response(data=items_as_dicts, pagination=pagination_info)
    else:
        # Page-based pagination
        query = f"{base_query}{order_clause}"
        items, pagination_info = await paginate_query(db, query, count_query, tuple(params), pagination)
        return success_response(data=items, pagination=pagination_info)


# ========================================
# Location/Search Suggestions API
# ========================================

@app.get("/api/locations/suggestions", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_location_suggestions(
    q: Optional[str] = Query(None, description="Search query"),
    limit: int = Query(20, ge=1, le=100),
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get location suggestions for search autocomplete.
    Returns suburbs and postcodes with property counts.
    """
    try:
        if q and len(q.strip()) > 0:
            # Search with query
            search_term = q.strip().lower()
            
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as clean_postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL
                AND is_active = TRUE
                AND (
                    LOWER(suburb) LIKE %s
                    OR REPLACE(postcode, '.0', '') LIKE %s
                )
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY 
                CASE 
                    WHEN LOWER(suburb) = %s THEN 1
                    WHEN LOWER(suburb) LIKE %s THEN 2
                    ELSE 3
                END,
                property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (
                        f'%{search_term}%',
                        f'{search_term}%',
                        search_term,
                        f'{search_term}%',
                        limit
                    ))
                    results = cur.fetchall()
                    return results
            
            results = await asyncio.to_thread(_db_call)
            
            # Format results
            suggestions = []
            for row in results:
                suburb = row[0]
                postcode = row[1]
                count = row[2]
                
                suggestions.append({
                    "id": f"{suburb}_{postcode}",
                    "type": "suburb",
                    "name": suburb,
                    "postcode": postcode,
                    "fullName": f"{suburb}, NSW, {postcode}",
                    "count": count
                })
            
            return success_response(data=suggestions)
        
        else:
            # No query - return all locations
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (limit,))
                    results = cur.fetchall()
                    return results
            
            results = await asyncio.to_thread(_db_call)
            
            # Format results
            suggestions = []
            for row in results:
                suburb = row[0]
                postcode = row[1]
                count = row[2]
                
                suggestions.append({
                    "id": f"{suburb}_{postcode}",
                    "type": "suburb",
                    "name": suburb,
                    "postcode": postcode,
                    "fullName": f"{suburb}, NSW, {postcode}",
                    "count": count
                })
            
            return success_response(data=suggestions)
            
    except Exception as e:
        logger.error(f"Error getting location suggestions: {str(e)}")
        return error_response(f"Failed to get location suggestions: {str(e)}")


@app.get("/api/locations/all", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_all_locations(
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get all unique locations with property counts.
    Used for initializing search suggestions.
    """
    try:
        query = """
        SELECT 
            suburb,
            REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
            COUNT(DISTINCT listing_id) as property_count
        FROM properties
        WHERE suburb IS NOT NULL
          AND is_active = TRUE
        GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
        ORDER BY property_count DESC
        """
        
        def _db_call():
            with db.cursor() as cur:
                cur.execute(query)
                results = cur.fetchall()
                return results
        
        results = await asyncio.to_thread(_db_call)
        
        # Format results for both suburb and postcode lookups
        locations = []
        postcode_map = {}
        
        for row in results:
            suburb = row[0]
            postcode = row[1]
            count = row[2]
            
            # Add suburb entry
            locations.append({
                "id": f"{suburb}_{postcode}",
                "type": "suburb",
                "name": suburb,
                "postcode": postcode,
                "fullName": f"{suburb}, NSW, {postcode}",
                "count": count
            })
            
            # Aggregate by postcode
            if postcode not in postcode_map:
                postcode_map[postcode] = {
                    "id": f"postcode_{postcode}",
                    "type": "postcode",
                    "name": postcode,
                    "suburbs": [],
                    "fullName": f"{postcode}",
                    "count": 0
                }
            postcode_map[postcode]["suburbs"].append(suburb)
            postcode_map[postcode]["count"] += count
        
        # Update postcode fullNames with suburb list
        for postcode_data in postcode_map.values():
            suburbs_str = ", ".join(postcode_data["suburbs"][:3])  # Show first 3 suburbs
            if len(postcode_data["suburbs"]) > 3:
                suburbs_str += f" +{len(postcode_data['suburbs']) - 3} more"
            postcode_data["fullName"] = f"{postcode_data['name']} ({suburbs_str})"
            locations.append(postcode_data)
        
        # Sort by count
        locations.sort(key=lambda x: x["count"], reverse=True)
        
        return success_response(data=locations)
        
    except Exception as e:
        logger.error(f"Error getting all locations: {str(e)}")
        return error_response(f"Failed to get locations: {str(e)}")


@app.get("/api/locations/nearby", tags=["Locations"])
@cache(expire=900)  # Cache for 15 minutes
async def get_nearby_suburbs(
    suburb: str = Query(..., description="Suburb name"),
    limit: int = Query(6, ge=1, le=20),
    db: Any = Depends(get_db_conn_dependency)
):
    """
    Get nearby suburbs based on the selected suburb.
    Returns suggested suburbs that users might also be interested in.
    """
    # Define nearby suburbs mapping (Sydney area)
    nearby_mapping = {
        "Sydney": ["Haymarket", "Surry Hills", "Pyrmont", "Ultimo", "The Rocks", "Darling Harbour"],
        "Ultimo": ["Sydney", "Chippendale", "Pyrmont", "Glebe", "Surry Hills", "Camperdown"],
        "Chippendale": ["Ultimo", "Redfern", "Darlington", "Glebe", "Newtown", "Camperdown"],
        "Surry Hills": ["Sydney", "Darlinghurst", "Paddington", "Redfern", "Moore Park", "Elizabeth Bay"],
        "Redfern": ["Chippendale", "Surry Hills", "Waterloo", "Alexandria", "Eveleigh", "Darlington"],
        "Newtown": ["Erskineville", "Enmore", "Stanmore", "Camperdown", "Marrickville", "St Peters"],
        "Glebe": ["Ultimo", "Forest Lodge", "Annandale", "Camperdown", "Leichhardt", "Pyrmont"],
        "Pyrmont": ["Sydney", "Ultimo", "Glebe", "Balmain", "Rozelle", "Barangaroo"],
        "Waterloo": ["Redfern", "Alexandria", "Zetland", "Rosebery", "Surry Hills", "Moore Park"],
        "Alexandria": ["Waterloo", "Redfern", "Erskineville", "Beaconsfield", "Rosebery", "Mascot"],
        "Zetland": ["Waterloo", "Rosebery", "Kensington", "Alexandria", "Beaconsfield", "Green Square"],
        "Rosebery": ["Zetland", "Waterloo", "Alexandria", "Mascot", "Beaconsfield", "Eastlakes"],
        "Mascot": ["Rosebery", "Alexandria", "Botany", "Eastlakes", "Pagewood", "Wolli Creek"],
        "Randwick": ["Kensington", "Kingsford", "Coogee", "Clovelly", "Centennial Park", "Queens Park"],
        "Kensington": ["Randwick", "Kingsford", "Zetland", "Centennial Park", "Moore Park", "Rosebery"],
        "Kingsford": ["Randwick", "Kensington", "Maroubra", "Daceyville", "Eastlakes", "Coogee"],
        "Maroubra": ["Kingsford", "Pagewood", "Hillsdale", "Malabar", "Coogee", "South Coogee"],
        "Hurstville": ["Penshurst", "Allawah", "Mortdale", "Beverley Park", "Peakhurst", "Oatley"],
        "Burwood": ["Strathfield", "Croydon", "Ashfield", "Five Dock", "Concord", "Homebush"],
        "Campsie": ["Canterbury", "Belmore", "Lakemba", "Ashbury", "Clemton Park", "Earlwood"],
        "Parramatta": ["Westmead", "Harris Park", "North Parramatta", "Rosehill", "Granville", "Rydalmere"],
        "Chatswood": ["Artarmon", "Willoughby", "Lane Cove", "Roseville", "Lindfield", "North Willoughby"],
        "North Sydney": ["Milsons Point", "Kirribilli", "Neutral Bay", "Waverton", "McMahons Point", "Crows Nest"],
        "Bondi": ["Bondi Beach", "North Bondi", "Tamarama", "Bellevue Hill", "Waverley", "Bondi Junction"],
        "Coogee": ["Randwick", "South Coogee", "Clovelly", "Maroubra", "Kingsford", "Bronte"]
    }
    
    try:
        # Get nearby suburbs from mapping
        nearby_suburbs = nearby_mapping.get(suburb, [])[:limit]
        
        if not nearby_suburbs:
            # If no mapping found, return popular suburbs as fallback
            query = """
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IS NOT NULL AND suburb != %s
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            LIMIT %s
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, (suburb, limit))
                    results = cur.fetchall()
                    return results
            
            results = await asyncio.to_thread(_db_call)
        else:
            # Get data for nearby suburbs
            placeholders = ','.join(['%s'] * len(nearby_suburbs))
            query = f"""
            SELECT 
                suburb,
                REPLACE(COALESCE(postcode, '0'), '.0', '') as postcode,
                COUNT(DISTINCT listing_id) as property_count
            FROM properties
            WHERE suburb IN ({placeholders})
              AND is_active = TRUE
            GROUP BY suburb, REPLACE(COALESCE(postcode, '0'), '.0', '')
            ORDER BY property_count DESC
            """
            
            def _db_call():
                with db.cursor() as cur:
                    cur.execute(query, nearby_suburbs)
                    results = cur.fetchall()
                    return results
            
            results = await asyncio.to_thread(_db_call)
        
        # Format results
        suggestions = []
        for row in results:
            suburb_name = row[0]
            postcode = row[1]
            count = row[2]
            
            suggestions.append({
                "id": f"{suburb_name}_{postcode}",
                "type": "suburb",
                "name": suburb_name,
                "postcode": postcode,
                "fullName": f"{suburb_name}, NSW, {postcode}",
                "count": count
            })
        
        return success_response(data={
            "current": suburb,
            "nearby": suggestions
        })
        
    except Exception as e:
        logger.error(f"Error getting nearby suburbs: {str(e)}")
        return error_response(f"Failed to get nearby suburbs: {str(e)}")
