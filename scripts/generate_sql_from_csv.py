import pandas as pd
import os
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def escape_sql_string(value):
    """Escapes a string for SQL insertion."""
    if value is None:
        return "NULL"
    # Replace single quotes with two single quotes
    return "'" + str(value).replace("'", "''") + "'"

def generate_sql_inserts():
    """Reads the latest CSV and generates SQL INSERT statements."""
    csv_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'crawler', 'dist', 'output', '20250710_145022_results.csv')
    sql_output_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'database', 'manual_import.sql')

    if not os.path.exists(csv_file_path):
        logging.error(f"CSV file not found at: {csv_file_path}")
        return

    logging.info(f"Reading CSV file from: {csv_file_path}")
    try:
        df = pd.read_csv(csv_file_path, keep_default_na=True, na_values=['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', 'NA'])
    except Exception as e:
        logging.error(f"Error reading CSV file: {e}")
        return

    logging.info(f"Successfully read {len(df)} rows from CSV.")
    
    # Data cleaning from process_csv.py
    bool_cols = [
        'has_air_conditioning', 'is_furnished', 'has_balcony', 'has_dishwasher',
        'has_laundry', 'has_built_in_wardrobe', 'has_gym', 'has_pool',
        'has_parking', 'allows_pets', 'has_security_system', 'has_storage',
        'has_study_room', 'has_garden'
    ]
    for col in bool_cols:
        if col in df.columns:
            df[col] = df[col].astype(str).str.upper().map({'TRUE': True, 'FALSE': False, 'YES': True, 'NO': False, '1': True, '0': False}).fillna(False).astype(bool)
        else:
            df[col] = False

    numeric_cols = ['rent_pw', 'bond', 'bedrooms', 'bathrooms', 'parking_spaces']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
        else:
            df[col] = 0

    if 'available_date' in df.columns:
        df['available_date'] = pd.to_datetime(df['available_date'], errors='coerce').dt.date
    else:
        df['available_date'] = None

    if 'latitude' in df.columns and 'longitude' in df.columns:
        df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')
        df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')
        df['geom'] = df.apply(
            lambda row: f"SRID=4326;POINT({row['longitude']} {row['latitude']})"
            if pd.notnull(row['longitude']) and pd.notnull(row['latitude']) else None,
            axis=1
        )
    else:
        df['geom'] = None

    json_cols = ['images', 'property_features']
    for col in json_cols:
        if col in df.columns:
            df[col] = df[col].apply(lambda x: x if isinstance(x, str) and x.strip() and x.strip() != '[]' else None)
        else:
            df[col] = None

    df.drop_duplicates(subset=['listing_id'], keep='first', inplace=True)

    with open(sql_output_path, 'w', encoding='utf-8') as f:
        f.write("-- Manual SQL Import Script for Properties\n")
        f.write("-- Generated by Cline\n\n")
        
        for index, row in df.iterrows():
            columns = []
            values = []
            
            for col in row.index:
                if pd.notna(row[col]):
                    columns.append(col)
                    value = row[col]
                    if isinstance(value, str):
                        values.append(escape_sql_string(value))
                    elif isinstance(value, bool):
                        values.append(str(value).upper())
                    else:
                        values.append(str(value))
                
            if 'listing_id' in columns:
                insert_statement = f"INSERT INTO properties ({', '.join(columns)}) VALUES ({', '.join(values)});\n"
                f.write(insert_statement)

    logging.info(f"SQL INSERT statements have been written to: {sql_output_path}")

if __name__ == "__main__":
    generate_sql_inserts()
